{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1822622",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-24T15:03:53.854550Z",
     "iopub.status.busy": "2022-04-24T15:03:53.853568Z",
     "iopub.status.idle": "2022-04-24T15:03:53.872218Z",
     "shell.execute_reply": "2022-04-24T15:03:53.872663Z",
     "shell.execute_reply.started": "2022-04-24T14:53:45.316233Z"
    },
    "papermill": {
     "duration": 0.058222,
     "end_time": "2022-04-24T15:03:53.872936",
     "exception": false,
     "start_time": "2022-04-24T15:03:53.814714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n",
      "[GCC 9.4.0]\n",
      "/kaggle/input/lstmfile/ckpt_.data-00000-of-00001\n",
      "/kaggle/input/lstmfile/LSTM.tflite\n",
      "/kaggle/input/lstmfile/tokenizer.pickle\n",
      "/kaggle/input/lstmfile/ckpt_.index\n",
      "/kaggle/input/lstmfile/simplified_model.h5\n",
      "/kaggle/input/lstmfile/baselineModel.h5\n",
      "/kaggle/input/lstmfile/checkpoint\n",
      "/kaggle/input/newencoded/encodedNew.csv\n",
      "/kaggle/input ['lstmfile', 'newencoded']\n",
      "/kaggle/input/lstmfile []\n",
      "/kaggle/input/newencoded []\n"
     ]
    }
   ],
   "source": [
    "#!pip list\n",
    "\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "count = 0\n",
    "for root, folders, filenames in os.walk('/kaggle/input'):\n",
    "   print(root, folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf16c948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:03:53.929947Z",
     "iopub.status.busy": "2022-04-24T15:03:53.929151Z",
     "iopub.status.idle": "2022-04-24T15:03:53.931214Z",
     "shell.execute_reply": "2022-04-24T15:03:53.931579Z",
     "shell.execute_reply.started": "2022-04-24T14:53:45.341472Z"
    },
    "papermill": {
     "duration": 0.033315,
     "end_time": "2022-04-24T15:03:53.931727",
     "exception": false,
     "start_time": "2022-04-24T15:03:53.898412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        units=rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True, #look into this causing the issue potentially, originally was True\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal() #used to be be tf.keras.initializers.GlorotNormal() before downgradingf\n",
    "    )) # temp removed\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef103335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:03:53.992257Z",
     "iopub.status.busy": "2022-04-24T15:03:53.991626Z",
     "iopub.status.idle": "2022-04-24T15:03:59.513201Z",
     "shell.execute_reply": "2022-04-24T15:03:59.512660Z",
     "shell.execute_reply.started": "2022-04-24T14:53:45.351322Z"
    },
    "papermill": {
     "duration": 5.552475,
     "end_time": "2022-04-24T15:03:59.513330",
     "exception": false,
     "start_time": "2022-04-24T15:03:53.960855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf # ML/DL\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "import tensorflow_addons as tfa\n",
    "#import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d668c758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:03:59.567321Z",
     "iopub.status.busy": "2022-04-24T15:03:59.566521Z",
     "iopub.status.idle": "2022-04-24T15:03:59.597719Z",
     "shell.execute_reply": "2022-04-24T15:03:59.598183Z",
     "shell.execute_reply.started": "2022-04-24T14:53:47.112256Z"
    },
    "papermill": {
     "duration": 0.059179,
     "end_time": "2022-04-24T15:03:59.598334",
     "exception": false,
     "start_time": "2022-04-24T15:03:59.539155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d/l</th>\n",
       "      <th>pu</th>\n",
       "      <th>tpu</th>\n",
       "      <th>rpu</th>\n",
       "      <th>su</th>\n",
       "      <th>tsu</th>\n",
       "      <th>rsu</th>\n",
       "      <th>sq</th>\n",
       "      <th>tsq</th>\n",
       "      <th>rsq</th>\n",
       "      <th>bp</th>\n",
       "      <th>tbp</th>\n",
       "      <th>rbp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
       "0    4   8   10   18  25   35   42  56   70    2  63   80    0\n",
       "1    1   3   25   28   3   15   61   7   50    6   6   50   25\n",
       "2    2  21   55   19  24   70   10  10   30    2  13   40   27\n",
       "3    2  12   30   45  12   35    6   8   25    7  28   80    0\n",
       "4    4  11   15   53  12   15    5  20   25   36  48   60   17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try: #for recursive model training\n",
    "#    df = pd.read_csv(os.path.join('./WORKING'))\n",
    "#    print('Wokrgin')\n",
    "#except:\n",
    "df = pd.read_csv(os.path.join('../input/newencoded/encodedNew.csv'))\n",
    "#OG DATAFRAME\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc52de5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:03:59.681814Z",
     "iopub.status.busy": "2022-04-24T15:03:59.658799Z",
     "iopub.status.idle": "2022-04-24T15:03:59.683518Z",
     "shell.execute_reply": "2022-04-24T15:03:59.683098Z",
     "shell.execute_reply.started": "2022-04-24T14:53:47.135337Z"
    },
    "papermill": {
     "duration": 0.059463,
     "end_time": "2022-04-24T15:03:59.683640",
     "exception": false,
     "start_time": "2022-04-24T15:03:59.624177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def alterRange(pu,tpu): #THE MODEL DOESNT CONTAIN ALL THE VOCAB WE ARE ASKING IT TO, EITHER MAP TO CLOSEST VOCAB OR RETAIN THE MOBEL ON MORE POSSIBLE NUMBER\n",
    "    mul = pu/tpu\n",
    "    alterMul = mul + 1.0 #should be 0.03 but ill make it 0.5 for now\n",
    "    pu = alterMul * tpu  \n",
    "    return int(float(pu))\n",
    "\n",
    "\n",
    "def generateAction(diffLevel):\n",
    "    if diffLevel == 5: \n",
    "        multiplier = random.uniform(0.9,1)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 4: \n",
    "        multiplier = random.uniform(0.7,0.8)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 3: \n",
    "        multiplier = random.uniform(0.5,0.6)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 2: \n",
    "        multiplier = random.uniform(0.3,0.4)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 1: \n",
    "        multiplier = random.uniform(0.1,0.2)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    return tpa,numActions,rpa\n",
    "\n",
    "def generateExamples(diffLevel, alter=False):\n",
    "    if diffLevel == 5: \n",
    "        tpu,pu,rpu = generateAction(5)\n",
    "        tsu,su,rsu = generateAction(5)\n",
    "        tsq,sq,rsq = generateAction(5)\n",
    "        tbp,bp,rbp = generateAction(5)\n",
    "        print(pu)\n",
    "        #temp\n",
    "        if(alter == True):\n",
    "            pu = alterRange(pu,tpu)\n",
    "        #temp\n",
    "        print(pu)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "        #outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 4: \n",
    "        tpu,pu,rpu = generateAction(4)\n",
    "        tsu,su,rsu = generateAction(4)\n",
    "        tsq,sq,rsq = generateAction(4)\n",
    "        tbp,bp,rbp = generateAction(4)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 3: \n",
    "        tpu,pu,rpu = generateAction(3)\n",
    "        tsu,su,rsu = generateAction(3)\n",
    "        tsq,sq,rsq = generateAction(3)\n",
    "        tbp,bp,rbp = generateAction(3)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 2: \n",
    "        tpu,pu,rpu = generateAction(2)\n",
    "        tsu,su,rsu = generateAction(2)\n",
    "        tsq,sq,rsq = generateAction(2)\n",
    "        tbp,bp,rbp = generateAction(2)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 1: \n",
    "        tpu,pu,rpu = generateAction(1)\n",
    "        tsu,su,rsu = generateAction(1)\n",
    "        tsq,sq,rsq = generateAction(1)\n",
    "        tbp,bp,rbp = generateAction(1)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    return outputStr\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935b342e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:03:59.748989Z",
     "iopub.status.busy": "2022-04-24T15:03:59.748295Z",
     "iopub.status.idle": "2022-04-24T15:04:01.196808Z",
     "shell.execute_reply": "2022-04-24T15:04:01.196197Z",
     "shell.execute_reply.started": "2022-04-24T14:53:47.165516Z"
    },
    "papermill": {
     "duration": 1.487682,
     "end_time": "2022-04-24T15:04:01.196962",
     "exception": false,
     "start_time": "2022-04-24T15:03:59.709280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
      "0    4   8   10   18  25   35   42  56   70    2  63   80    0\n",
      "1    1   3   25   28   3   15   61   7   50    6   6   50   25\n",
      "2    2  21   55   19  24   70   10  10   30    2  13   40   27\n",
      "3    2  12   30   45  12   35    6   8   25    7  28   80    0\n",
      "4    4  11   15   53  12   15    5  20   25   36  48   60   17\n",
      "      d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
      "537     4  41   55    5  64   80    0  40   55    7  11   15   47\n",
      "770     4  23   30   15   7   10   59  24   30   19  52   70    4\n",
      "922     3  29   50    5  11   20   28  36   70   10  21   35    9\n",
      "43      4  15   20   60  24   30   17  18   25   45  28   35   24\n",
      "1231    1   8   40   21  15   80    0   6   50   19   7   60   11\n",
      "9\n",
      "19\n",
      "46\n",
      "96\n",
      "51\n",
      "106\n",
      "49\n",
      "99\n",
      "24\n",
      "49\n",
      "38\n",
      "78\n",
      "24\n",
      "49\n",
      "46\n",
      "96\n",
      "69\n",
      "144\n",
      "37\n",
      "77\n",
      "72\n",
      "147\n",
      "27\n",
      "57\n",
      "9\n",
      "19\n",
      "65\n",
      "135\n",
      "66\n",
      "136\n",
      "22\n",
      "47\n",
      "32\n",
      "67\n",
      "14\n",
      "29\n",
      "65\n",
      "135\n",
      "51\n",
      "106\n",
      "68\n",
      "138\n",
      "73\n",
      "148\n",
      "18\n",
      "38\n",
      "67\n",
      "137\n",
      "36\n",
      "76\n",
      "34\n",
      "69\n",
      "56\n",
      "116\n",
      "13\n",
      "28\n",
      "46\n",
      "96\n",
      "58\n",
      "118\n",
      "22\n",
      "47\n",
      "37\n",
      "77\n",
      "58\n",
      "118\n",
      "39\n",
      "79\n",
      "61\n",
      "126\n",
      "27\n",
      "57\n",
      "19\n",
      "39\n",
      "49\n",
      "104\n",
      "23\n",
      "48\n",
      "38\n",
      "78\n",
      "73\n",
      "148\n",
      "24\n",
      "49\n",
      "46\n",
      "96\n",
      "66\n",
      "136\n",
      "61\n",
      "126\n",
      "59\n",
      "123\n",
      "65\n",
      "135\n",
      "68\n",
      "138\n",
      "49\n",
      "104\n",
      "63\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "STOP_SIGN = \"␣\"   \n",
    "allWorkoutsString = []\n",
    "stringVocab = []\n",
    "\n",
    "#import random\n",
    "\n",
    "\n",
    "##NEW SHUFFLING TO FIX POOR EARLY PERFORMANCE\n",
    "print(df.head())\n",
    "df = df.sample(frac = 1)\n",
    "print(df.head())\n",
    "##NEW SHUFFLING TO FIX POOR EARLY PERFORMANCE\n",
    "\n",
    "for i in range(len(df)):\n",
    "    #df.iloc[i][\"pu\"] = alterRange(df.iloc[i][\"pu\"],df.iloc[i][\"tpu\"]) #right now it overall makes pu way more diffiuclt\n",
    "    workout = (str(df.iloc[i][\"d/l\"]) + \"-DL:~\" + str(df.iloc[i][\"pu\"]) + \"~\" + str(df.iloc[i][\"tpu\"]) + \"~\" + str(df.iloc[i][\"rpu\"]) + \"~\" + str(df.iloc[i][\"su\"]) + \"~\" + str(df.iloc[i][\"tsu\"]) + \"~\" + str(df.iloc[i][\"rsu\"]) + \"~\" + str(df.iloc[i][\"sq\"]) + \"~\" + str(df.iloc[i][\"tsq\"]) + \"~\" + str(df.iloc[i][\"rsq\"]) + \"~\"  +  str(df.iloc[i][\"bp\"]) + \"~\" + str(df.iloc[i][\"tbp\"]) + \"~\" + str(df.iloc[i][\"rbp\"]) + \"~\" + \"␣\" )\n",
    "    #allWorkoutsString.append(workout)\n",
    "    stringVocab.append(workout)\n",
    "      \n",
    "        \n",
    "\n",
    "#df.to_csv(\"./WORKING\")\n",
    "#\n",
    "for z in range(50):   \n",
    "    allWorkoutsString.append(generateExamples(5,True))\n",
    "    #allWorkoutsString.append(generateExamples(4))\n",
    "    #allWorkoutsString.append(generateExamples(3))\n",
    "    #allWorkoutsString.append(generateExamples(2))\n",
    "    #allWorkoutsString.append(generateExamples(1))\n",
    "    \n",
    "#allWorkoutsString.append(generateExamples(5,True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01931a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:01.265611Z",
     "iopub.status.busy": "2022-04-24T15:04:01.264693Z",
     "iopub.status.idle": "2022-04-24T15:04:01.266557Z",
     "shell.execute_reply": "2022-04-24T15:04:01.267022Z",
     "shell.execute_reply.started": "2022-04-24T14:53:48.600075Z"
    },
    "papermill": {
     "duration": 0.04143,
     "end_time": "2022-04-24T15:04:01.267175",
     "exception": false,
     "start_time": "2022-04-24T15:04:01.225745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decodeWorkout(input):    \n",
    "    c = input.split(\"~\")\n",
    "    if(len(c) == 5):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        outputStr = (pushupStr)\n",
    "    elif(len(c) == 8):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr)\n",
    "    elif(len(c)==11):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        squatStr = str(\"\\n\" + c[7] + \" squats for \" + c[8] + \" seconds with \" + c[9] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr + squatStr)\n",
    "    elif(len(c) == 14):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        squatStr = str(\"\\n\" + c[7] + \" squats for \" + c[8] + \" seconds with \" + c[9] + \" second rest \")\n",
    "        burpeeStr = str(\"\\n\" + c[10] + \" burpees for \" + c[11] + \" seconds with \" + c[12] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr + squatStr + burpeeStr)\n",
    "    else:\n",
    "        outputStr = \"fail\"\n",
    "    \n",
    "    return outputStr\n",
    "#for i in range(15) :\n",
    "#        print(decodeWorkout(allWorkoutsString[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f061e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:01.327119Z",
     "iopub.status.busy": "2022-04-24T15:04:01.324770Z",
     "iopub.status.idle": "2022-04-24T15:04:01.336653Z",
     "shell.execute_reply": "2022-04-24T15:04:01.337268Z",
     "shell.execute_reply.started": "2022-04-24T14:53:48.614506Z"
    },
    "papermill": {
     "duration": 0.044236,
     "end_time": "2022-04-24T15:04:01.337444",
     "exception": false,
     "start_time": "2022-04-24T15:04:01.293208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_words': None, 'filters': '', 'lower': False, 'split': '', 'char_level': True, 'oov_token': None, 'document_count': 1500, 'word_counts': '{\"5\": 5707, \"-\": 1500, \"D\": 1500, \"L\": 1500, \":\": 1500, \"~\": 19500, \"2\": 4330, \"7\": 1901, \"3\": 3542, \"0\": 4869, \"1\": 4829, \"6\": 2221, \"4\": 3507, \"\\\\u2423\": 1500, \"9\": 1132, \"8\": 1554}', 'word_docs': '{\"5\": 1472, \"~\": 1500, \"L\": 1500, \"0\": 1479, \"1\": 1435, \"6\": 1182, \"-\": 1500, \"3\": 1347, \":\": 1500, \"4\": 1360, \"2\": 1406, \"7\": 1095, \"\\\\u2423\": 1500, \"D\": 1500, \"9\": 835, \"8\": 1005}', 'index_docs': '{\"2\": 1472, \"1\": 1500, \"13\": 1500, \"3\": 1479, \"4\": 1435, \"8\": 1182, \"11\": 1500, \"6\": 1347, \"14\": 1500, \"7\": 1360, \"5\": 1406, \"9\": 1095, \"15\": 1500, \"12\": 1500, \"16\": 835, \"10\": 1005}', 'index_word': '{\"1\": \"~\", \"2\": \"5\", \"3\": \"0\", \"4\": \"1\", \"5\": \"2\", \"6\": \"3\", \"7\": \"4\", \"8\": \"6\", \"9\": \"7\", \"10\": \"8\", \"11\": \"-\", \"12\": \"D\", \"13\": \"L\", \"14\": \":\", \"15\": \"\\\\u2423\", \"16\": \"9\"}', 'word_index': '{\"~\": 1, \"5\": 2, \"0\": 3, \"1\": 4, \"2\": 5, \"3\": 6, \"4\": 7, \"6\": 8, \"7\": 9, \"8\": 10, \"-\": 11, \"D\": 12, \"L\": 13, \":\": 14, \"\\\\u2423\": 15, \"9\": 16}'}\n",
      "Vectorized dataset size 50\n",
      "[[3]]\n",
      "[[4]]\n",
      "[[5]]\n",
      "[[6]]\n",
      "[[7]]\n",
      "[[2]]\n",
      "[[8]]\n",
      "[[9]]\n",
      "[[10]]\n",
      "[[16]]\n"
     ]
    }
   ],
   "source": [
    "#encoding each of the characters into integers so the model can understand -> paying special attention to the stop_sign\n",
    "import pickle\n",
    "\n",
    "with open('../input/lstmfile/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "\n",
    "print(tokenizer.get_config())\n",
    "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1 \n",
    "\n",
    "dataset_vectorized = tokenizer.texts_to_sequences(allWorkoutsString)\n",
    "print('Vectorized dataset size', len(dataset_vectorized))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(tokenizer.texts_to_sequences([f\"{i}\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "735defd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:01.401541Z",
     "iopub.status.busy": "2022-04-24T15:04:01.400517Z",
     "iopub.status.idle": "2022-04-24T15:04:01.405194Z",
     "shell.execute_reply": "2022-04-24T15:04:01.404682Z",
     "shell.execute_reply.started": "2022-04-24T14:53:48.63274Z"
    },
    "papermill": {
     "duration": 0.039284,
     "end_time": "2022-04-24T15:04:01.405334",
     "exception": false,
     "start_time": "2022-04-24T15:04:01.366050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "#add padding to ensure same length --- only if all are not the sane length\n",
    "print(len(dataset_vectorized))\n",
    "maxLength = 0\n",
    "for workout_index, workout in enumerate(dataset_vectorized[:len(dataset_vectorized)]):\n",
    "    #if(len(workout)) != 167:\n",
    "    if(maxLength < len(workout)):\n",
    "        #print('Workout #{} length: {}'.format(workout_index + 1, len(workout)))\n",
    "        maxLength = len(workout)\n",
    "#padding is required\n",
    "print(maxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45af71e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:01.473356Z",
     "iopub.status.busy": "2022-04-24T15:04:01.472381Z",
     "iopub.status.idle": "2022-04-24T15:04:01.475831Z",
     "shell.execute_reply": "2022-04-24T15:04:01.476403Z",
     "shell.execute_reply.started": "2022-04-24T14:53:48.641464Z"
    },
    "papermill": {
     "duration": 0.039885,
     "end_time": "2022-04-24T15:04:01.476566",
     "exception": false,
     "start_time": "2022-04-24T15:04:01.436681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - D L : ~ 1 9 ~ 1 0 ~ 1 0 ~ 1 8 ~ 2 0 ~ 2 7 ~ 4 4 ~ 4 5 ~ 4 ~ 5 1 ~ 5 5 ~ 2 1 ~ ␣\n"
     ]
    }
   ],
   "source": [
    "def decodeVector(vector):\n",
    "    decodedWorkout = tokenizer.sequences_to_texts([vector])[0]\n",
    "    print(decodedWorkout)\n",
    "    \n",
    "#basic test to see if the decoder is working\n",
    "decodeVector(dataset_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27c0a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:01.546334Z",
     "iopub.status.busy": "2022-04-24T15:04:01.545547Z",
     "iopub.status.idle": "2022-04-24T15:04:01.548780Z",
     "shell.execute_reply": "2022-04-24T15:04:01.549397Z",
     "shell.execute_reply.started": "2022-04-24T14:53:48.649892Z"
    },
    "papermill": {
     "duration": 0.041982,
     "end_time": "2022-04-24T15:04:01.549593",
     "exception": false,
     "start_time": "2022-04-24T15:04:01.507611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - D L : ~ 1 9 ~ 1 0 ~ 1 0 ~ 1 8 ~ 2 0 ~ 2 7 ~ 4 4 ~ 4 5 ~ 4 ~ 5 1 ~ 5 5 ~ 2 1 ~ ␣\n"
     ]
    }
   ],
   "source": [
    "dataset_vectorized_padded_without_stops = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    # We use -1 here and +1 in the next step to make sure\n",
    "    # that all recipes will have at least 1 stops sign at the end,\n",
    "    # since each sequence will be shifted and truncated afterwards\n",
    "    # (to generate X and Y sequences).\n",
    "    maxlen=maxLength-1,\n",
    "    #value=tokenizer.texts_to_sequences([STOP_SIGN])[0] #maybe append here again\n",
    ")\n",
    "dataset_vectorized_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized_padded_without_stops,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=maxLength+1,\n",
    "    #value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")\n",
    "\n",
    "for workout_index, workout in enumerate(dataset_vectorized_padded[:len(dataset_vectorized_padded)]):\n",
    "    if(len(workout)) != maxLength+1:\n",
    "        print('Workout #{} length: {}'.format(workout_index + 1, len(workout)))\n",
    "\n",
    "#test it out\n",
    "decodeVector(dataset_vectorized_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f6704bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:03.943635Z",
     "iopub.status.busy": "2022-04-24T15:04:03.942225Z",
     "iopub.status.idle": "2022-04-24T15:04:03.954193Z",
     "shell.execute_reply": "2022-04-24T15:04:03.955044Z",
     "shell.execute_reply.started": "2022-04-24T14:53:48.663415Z"
    },
    "papermill": {
     "duration": 2.375932,
     "end_time": "2022-04-24T15:04:03.955282",
     "exception": false,
     "start_time": "2022-04-24T15:04:01.579350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 15:04:01.681920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:01.775762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:01.776645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:01.779404: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 15:04:01.780185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:01.780931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:01.781548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:03.632620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:03.633478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:03.634270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:04:03.634986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dataset_vectorized_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90e38491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:04.020979Z",
     "iopub.status.busy": "2022-04-24T15:04:04.020363Z",
     "iopub.status.idle": "2022-04-24T15:04:04.091466Z",
     "shell.execute_reply": "2022-04-24T15:04:04.092101Z",
     "shell.execute_reply.started": "2022-04-24T14:53:49.613736Z"
    },
    "papermill": {
     "duration": 0.106938,
     "end_time": "2022-04-24T15:04:04.092303",
     "exception": false,
     "start_time": "2022-04-24T15:04:03.985365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((44,), (44,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "#split processing\n",
    "def split_input_target(workout):\n",
    "    input_text = workout[:-1]\n",
    "    target_text = workout[1:]\n",
    "    \n",
    "    return input_text, target_text\n",
    "dataset_targeted = dataset.map(split_input_target)\n",
    "print(dataset_targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dbe3dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:04.153301Z",
     "iopub.status.busy": "2022-04-24T15:04:04.152504Z",
     "iopub.status.idle": "2022-04-24T15:04:04.158948Z",
     "shell.execute_reply": "2022-04-24T15:04:04.158470Z",
     "shell.execute_reply.started": "2022-04-24T14:53:49.673739Z"
    },
    "papermill": {
     "duration": 0.037135,
     "end_time": "2022-04-24T15:04:04.159073",
     "exception": false,
     "start_time": "2022-04-24T15:04:04.121938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "#compile\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #used to be 0.001 which worked much better\n",
    "\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f741065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:04.220301Z",
     "iopub.status.busy": "2022-04-24T15:04:04.219620Z",
     "iopub.status.idle": "2022-04-24T15:04:04.283890Z",
     "shell.execute_reply": "2022-04-24T15:04:04.283335Z",
     "shell.execute_reply.started": "2022-04-24T14:53:49.682421Z"
    },
    "papermill": {
     "duration": 0.09708,
     "end_time": "2022-04-24T15:04:04.284042",
     "exception": false,
     "start_time": "2022-04-24T15:04:04.186962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a checkpoints directory. TO SAVE AND CONTINUE TRAINING\n",
    "checkpoint_dir = 'tmp/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_') #used to be ckpt_{epoch}, got rid due to space issues on kaggle\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98fada29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:04.346121Z",
     "iopub.status.busy": "2022-04-24T15:04:04.345339Z",
     "iopub.status.idle": "2022-04-24T15:04:05.201397Z",
     "shell.execute_reply": "2022-04-24T15:04:05.202047Z",
     "shell.execute_reply.started": "2022-04-24T14:53:49.730628Z"
    },
    "papermill": {
     "duration": 0.890029,
     "end_time": "2022-04-24T15:04:05.202276",
     "exception": false,
     "start_time": "2022-04-24T15:04:04.312247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "#model = keras.models.load_model(\n",
    "#    \"../input/lstmfile/baselineModel.h5\", custom_objects={\"loss\": loss}\n",
    "#)\n",
    "\n",
    "\n",
    "model = keras.models.load_model(\"../input/lstmfile/simplified_model.h5\")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=loss\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fadb8112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:05.308094Z",
     "iopub.status.busy": "2022-04-24T15:04:05.304648Z",
     "iopub.status.idle": "2022-04-24T15:04:05.324798Z",
     "shell.execute_reply": "2022-04-24T15:04:05.324114Z",
     "shell.execute_reply.started": "2022-04-24T14:53:50.585935Z"
    },
    "papermill": {
     "duration": 0.074362,
     "end_time": "2022-04-24T15:04:05.324973",
     "exception": false,
     "start_time": "2022-04-24T15:04:05.250611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((1, 44), (1, 44)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# Batch size.\n",
    "BATCH_SIZE = 1\n",
    "# Buffer size to shuffle the dataset (TF data is designed to work\n",
    "# with possibly infinite sequences, so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in\n",
    "# which it shuffles elements).\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "dataset_train = dataset_targeted \\\n",
    "  .shuffle(SHUFFLE_BUFFER_SIZE) \\\n",
    "  .batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "  .repeat()\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8ae9752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:05.457976Z",
     "iopub.status.busy": "2022-04-24T15:04:05.456813Z",
     "iopub.status.idle": "2022-04-24T15:04:05.462241Z",
     "shell.execute_reply": "2022-04-24T15:04:05.458832Z",
     "shell.execute_reply.started": "2022-04-24T14:53:50.596947Z"
    },
    "papermill": {
     "duration": 0.075861,
     "end_time": "2022-04-24T15:04:05.462525",
     "exception": false,
     "start_time": "2022-04-24T15:04:05.386664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:           3\n",
      "INITIAL_EPOCH:    1\n",
      "STEPS_PER_EPOCH:  1\n"
     ]
    }
   ],
   "source": [
    "#const\n",
    "EPOCHS = 3 #5 seemed to work well\n",
    "INITIAL_EPOCH = 1\n",
    "STEPS_PER_EPOCH = 1  #len(allWorkoutsString) / BATCH_SIZE\n",
    "print('EPOCHS:          ', EPOCHS) \n",
    "print('INITIAL_EPOCH:   ', INITIAL_EPOCH)\n",
    "print('STEPS_PER_EPOCH: ', STEPS_PER_EPOCH) #default was 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e64e2282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:05.596078Z",
     "iopub.status.busy": "2022-04-24T15:04:05.593874Z",
     "iopub.status.idle": "2022-04-24T15:04:09.551119Z",
     "shell.execute_reply": "2022-04-24T15:04:09.551925Z",
     "shell.execute_reply.started": "2022-04-24T14:53:50.605742Z"
    },
    "papermill": {
     "duration": 4.027886,
     "end_time": "2022-04-24T15:04:09.552094",
     "exception": false,
     "start_time": "2022-04-24T15:04:05.524208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 15:04:07.046099: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-24 15:04:08.025759: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 3.1906\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8860\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=dataset_train,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        #tqdm_callback\n",
    "       # early_stopping_callback #we want to overfit this so get rid of early stopping\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07310b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:09.622661Z",
     "iopub.status.busy": "2022-04-24T15:04:09.621818Z",
     "iopub.status.idle": "2022-04-24T15:04:09.623992Z",
     "shell.execute_reply": "2022-04-24T15:04:09.624428Z",
     "shell.execute_reply.started": "2022-04-24T14:53:53.259324Z"
    },
    "papermill": {
     "duration": 0.041146,
     "end_time": "2022-04-24T15:04:09.624574",
     "exception": false,
     "start_time": "2022-04-24T15:04:09.583428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate = 1000, temperature=1.0):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    padded_start_string = start_string\n",
    "    # Converting our start string to numbers (vectorizing).\n",
    "    input_indices = np.array(tokenizer.texts_to_sequences([padded_start_string]))\n",
    "    # Empty string to store our results.\n",
    "    text_generated = []\n",
    "    # Here batch size == 1.\n",
    "   # model.reset_states()\n",
    "    for char_index in range(num_generate):\n",
    "        predictions = model(input_indices)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # Using a categorical distribution to predict the character returned by the model.\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions,\n",
    "            num_samples=1\n",
    "        )[-1, 0].numpy()\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state.\n",
    "        input_indices = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        next_character = tokenizer.sequences_to_texts(input_indices.numpy())[0]\n",
    "        text_generated.append(next_character)\n",
    "\n",
    "       # output = ''.join(text_generated)\n",
    "\n",
    "       # output = decodeWorkout(output)\n",
    "\n",
    "    return (padded_start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdee2989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:09.691360Z",
     "iopub.status.busy": "2022-04-24T15:04:09.690652Z",
     "iopub.status.idle": "2022-04-24T15:04:10.142612Z",
     "shell.execute_reply": "2022-04-24T15:04:10.142157Z",
     "shell.execute_reply.started": "2022-04-24T14:53:53.27124Z"
    },
    "papermill": {
     "duration": 0.487121,
     "end_time": "2022-04-24T15:04:10.142756",
     "exception": false,
     "start_time": "2022-04-24T15:04:09.655635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vocab_size=VOCABULARY_SIZE\n",
    "#embedding_dim=256\n",
    "#rnn_units=1024\n",
    "#\n",
    "#simplified_batch_size = 1\n",
    "#model_simplified = build_model(vocab_size, embedding_dim, rnn_units, simplified_batch_size)\n",
    "#model_simplified.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "#model_simplified.build(tf.TensorShape([simplified_batch_size, None]))\n",
    "#model_simplified.summary()\n",
    "\n",
    "nonTrainedModel = keras.models.load_model(\"../input/lstmfile/simplified_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50d9c803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:10.210438Z",
     "iopub.status.busy": "2022-04-24T15:04:10.209575Z",
     "iopub.status.idle": "2022-04-24T15:04:10.436177Z",
     "shell.execute_reply": "2022-04-24T15:04:10.436756Z",
     "shell.execute_reply.started": "2022-04-24T14:54:29.706753Z"
    },
    "papermill": {
     "duration": 0.263412,
     "end_time": "2022-04-24T15:04:10.436930",
     "exception": false,
     "start_time": "2022-04-24T15:04:10.173518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-DL:~52~45~22~64~65~8~54~60~18~24~25~44~49~40~29\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '5-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))\n",
    "\n",
    "#allWorkoutsString.append(\"5-DL:~60~50~28~14~15~17~15~15~36~34~35~5~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~40~30~6~10~10~5~44~45~6~41~45~16~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~75~65~9~24~25~45~41~45~34~72~80~0~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~85~70~0~55~55~3~33~35~23~30~30~34~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~60~50~22~68~75~4~63~70~6~14~15~33~␣\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7095d39f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:10.709178Z",
     "iopub.status.busy": "2022-04-24T15:04:10.708173Z",
     "iopub.status.idle": "2022-04-24T15:04:10.920967Z",
     "shell.execute_reply": "2022-04-24T15:04:10.921545Z",
     "shell.execute_reply.started": "2022-04-24T14:53:53.927094Z"
    },
    "papermill": {
     "duration": 0.453415,
     "end_time": "2022-04-24T15:04:10.921754",
     "exception": false,
     "start_time": "2022-04-24T15:04:10.468339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-DL:~␣\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '4-DL:', num_generate = 43, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8eee531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:10.991946Z",
     "iopub.status.busy": "2022-04-24T15:04:10.990550Z",
     "iopub.status.idle": "2022-04-24T15:04:11.200395Z",
     "shell.execute_reply": "2022-04-24T15:04:11.200800Z",
     "shell.execute_reply.started": "2022-04-24T14:53:54.252141Z"
    },
    "papermill": {
     "duration": 0.246789,
     "end_time": "2022-04-24T15:04:11.200955",
     "exception": false,
     "start_time": "2022-04-24T15:04:10.954166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-DL:~37~50~11~15~15~18~56~60~16~65~60~16~45~45~2\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '3-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05144685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:11.270367Z",
     "iopub.status.busy": "2022-04-24T15:04:11.269465Z",
     "iopub.status.idle": "2022-04-24T15:04:11.481218Z",
     "shell.execute_reply": "2022-04-24T15:04:11.481863Z",
     "shell.execute_reply.started": "2022-04-24T14:53:54.515531Z"
    },
    "papermill": {
     "duration": 0.249865,
     "end_time": "2022-04-24T15:04:11.482064",
     "exception": false,
     "start_time": "2022-04-24T15:04:11.232199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-DL:~25~29~45~45~14~48~60~16~69~70~10~25~25~44~4\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '2-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6d8ed36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:04:11.553551Z",
     "iopub.status.busy": "2022-04-24T15:04:11.552292Z",
     "iopub.status.idle": "2022-04-24T15:04:11.767329Z",
     "shell.execute_reply": "2022-04-24T15:04:11.766732Z",
     "shell.execute_reply.started": "2022-04-24T14:53:54.759611Z"
    },
    "papermill": {
     "duration": 0.252147,
     "end_time": "2022-04-24T15:04:11.767497",
     "exception": false,
     "start_time": "2022-04-24T15:04:11.515350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-DL:~␣\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '1-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35902e6",
   "metadata": {
    "papermill": {
     "duration": 0.048986,
     "end_time": "2022-04-24T15:04:11.873040",
     "exception": false,
     "start_time": "2022-04-24T15:04:11.824054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.39126,
   "end_time": "2022-04-24T15:04:14.657638",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-24T15:03:45.266378",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
