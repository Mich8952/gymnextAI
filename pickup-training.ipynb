{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440e6e92",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:35.563100Z",
     "iopub.status.busy": "2022-04-24T15:15:35.560254Z",
     "iopub.status.idle": "2022-04-24T15:15:35.598235Z",
     "shell.execute_reply": "2022-04-24T15:15:35.596647Z",
     "shell.execute_reply.started": "2022-04-24T15:14:24.989657Z"
    },
    "papermill": {
     "duration": 0.132905,
     "end_time": "2022-04-24T15:15:35.598489",
     "exception": false,
     "start_time": "2022-04-24T15:15:35.465584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n",
      "[GCC 9.4.0]\n",
      "/kaggle/input/newencoded/encodedNew.csv\n",
      "/kaggle/input/lstmfile/ckpt_.data-00000-of-00001\n",
      "/kaggle/input/lstmfile/LSTM.tflite\n",
      "/kaggle/input/lstmfile/tokenizer.pickle\n",
      "/kaggle/input/lstmfile/ckpt_.index\n",
      "/kaggle/input/lstmfile/simplified_model.h5\n",
      "/kaggle/input/lstmfile/baselineModel.h5\n",
      "/kaggle/input/lstmfile/checkpoint\n",
      "/kaggle/input ['newencoded', 'lstmfile']\n",
      "/kaggle/input/newencoded []\n",
      "/kaggle/input/lstmfile []\n"
     ]
    }
   ],
   "source": [
    "#!pip list\n",
    "\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "count = 0\n",
    "for root, folders, filenames in os.walk('/kaggle/input'):\n",
    "   print(root, folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe09bb16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:35.715968Z",
     "iopub.status.busy": "2022-04-24T15:15:35.714883Z",
     "iopub.status.idle": "2022-04-24T15:15:35.719162Z",
     "shell.execute_reply": "2022-04-24T15:15:35.719691Z",
     "shell.execute_reply.started": "2022-04-24T15:14:25.007916Z"
    },
    "papermill": {
     "duration": 0.063816,
     "end_time": "2022-04-24T15:15:35.719881",
     "exception": false,
     "start_time": "2022-04-24T15:15:35.656065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        units=rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True, #look into this causing the issue potentially, originally was True\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal() #used to be be tf.keras.initializers.GlorotNormal() before downgradingf\n",
    "    )) # temp removed\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a438d739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:35.833572Z",
     "iopub.status.busy": "2022-04-24T15:15:35.829405Z",
     "iopub.status.idle": "2022-04-24T15:15:41.991180Z",
     "shell.execute_reply": "2022-04-24T15:15:41.990310Z",
     "shell.execute_reply.started": "2022-04-24T15:14:25.016694Z"
    },
    "papermill": {
     "duration": 6.219745,
     "end_time": "2022-04-24T15:15:41.991340",
     "exception": false,
     "start_time": "2022-04-24T15:15:35.771595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf # ML/DL\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "import tensorflow_addons as tfa\n",
    "#import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413b75c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:42.059039Z",
     "iopub.status.busy": "2022-04-24T15:15:42.057697Z",
     "iopub.status.idle": "2022-04-24T15:15:42.089768Z",
     "shell.execute_reply": "2022-04-24T15:15:42.090302Z",
     "shell.execute_reply.started": "2022-04-24T15:14:25.028386Z"
    },
    "papermill": {
     "duration": 0.06852,
     "end_time": "2022-04-24T15:15:42.090459",
     "exception": false,
     "start_time": "2022-04-24T15:15:42.021939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d/l</th>\n",
       "      <th>pu</th>\n",
       "      <th>tpu</th>\n",
       "      <th>rpu</th>\n",
       "      <th>su</th>\n",
       "      <th>tsu</th>\n",
       "      <th>rsu</th>\n",
       "      <th>sq</th>\n",
       "      <th>tsq</th>\n",
       "      <th>rsq</th>\n",
       "      <th>bp</th>\n",
       "      <th>tbp</th>\n",
       "      <th>rbp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
       "0    4   8   10   18  25   35   42  56   70    2  63   80    0\n",
       "1    1   3   25   28   3   15   61   7   50    6   6   50   25\n",
       "2    2  21   55   19  24   70   10  10   30    2  13   40   27\n",
       "3    2  12   30   45  12   35    6   8   25    7  28   80    0\n",
       "4    4  11   15   53  12   15    5  20   25   36  48   60   17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try: #for recursive model training\n",
    "#    df = pd.read_csv(os.path.join('./WORKING'))\n",
    "#    print('Wokrgin')\n",
    "#except:\n",
    "df = pd.read_csv(os.path.join('../input/newencoded/encodedNew.csv'))\n",
    "#OG DATAFRAME\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fdd43e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:42.178193Z",
     "iopub.status.busy": "2022-04-24T15:15:42.167447Z",
     "iopub.status.idle": "2022-04-24T15:15:42.184444Z",
     "shell.execute_reply": "2022-04-24T15:15:42.184951Z",
     "shell.execute_reply.started": "2022-04-24T15:14:25.052611Z"
    },
    "papermill": {
     "duration": 0.065161,
     "end_time": "2022-04-24T15:15:42.185121",
     "exception": false,
     "start_time": "2022-04-24T15:15:42.119960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def alterRange(pu,tpu): #THE MODEL DOESNT CONTAIN ALL THE VOCAB WE ARE ASKING IT TO, EITHER MAP TO CLOSEST VOCAB OR RETAIN THE MOBEL ON MORE POSSIBLE NUMBER\n",
    "    mul = pu/tpu\n",
    "    alterMul = mul + 1.0 #should be 0.03 but ill make it 0.5 for now\n",
    "    pu = alterMul * tpu  \n",
    "    return int(float(pu))\n",
    "\n",
    "\n",
    "def generateAction(diffLevel):\n",
    "    if diffLevel == 5: \n",
    "        multiplier = random.uniform(0.9,1)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 4: \n",
    "        multiplier = random.uniform(0.7,0.8)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 3: \n",
    "        multiplier = random.uniform(0.5,0.6)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 2: \n",
    "        multiplier = random.uniform(0.3,0.4)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 1: \n",
    "        multiplier = random.uniform(0.1,0.2)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    return tpa,numActions,rpa\n",
    "\n",
    "def generateExamples(diffLevel, alter=False):\n",
    "    if diffLevel == 5: \n",
    "        tpu,pu,rpu = generateAction(5)\n",
    "        tsu,su,rsu = generateAction(5)\n",
    "        tsq,sq,rsq = generateAction(5)\n",
    "        tbp,bp,rbp = generateAction(5)\n",
    "        print(pu)\n",
    "        #temp\n",
    "        if(alter == True):\n",
    "            pu = alterRange(pu,tpu)\n",
    "        #temp\n",
    "        print(pu)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "        #outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 4: \n",
    "        tpu,pu,rpu = generateAction(4)\n",
    "        tsu,su,rsu = generateAction(4)\n",
    "        tsq,sq,rsq = generateAction(4)\n",
    "        tbp,bp,rbp = generateAction(4)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 3: \n",
    "        tpu,pu,rpu = generateAction(3)\n",
    "        tsu,su,rsu = generateAction(3)\n",
    "        tsq,sq,rsq = generateAction(3)\n",
    "        tbp,bp,rbp = generateAction(3)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 2: \n",
    "        tpu,pu,rpu = generateAction(2)\n",
    "        tsu,su,rsu = generateAction(2)\n",
    "        tsq,sq,rsq = generateAction(2)\n",
    "        tbp,bp,rbp = generateAction(2)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 1: \n",
    "        tpu,pu,rpu = generateAction(1)\n",
    "        tsu,su,rsu = generateAction(1)\n",
    "        tsq,sq,rsq = generateAction(1)\n",
    "        tbp,bp,rbp = generateAction(1)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    return outputStr\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b41077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:42.263435Z",
     "iopub.status.busy": "2022-04-24T15:15:42.262724Z",
     "iopub.status.idle": "2022-04-24T15:15:45.118886Z",
     "shell.execute_reply": "2022-04-24T15:15:45.117647Z",
     "shell.execute_reply.started": "2022-04-24T15:14:25.092560Z"
    },
    "papermill": {
     "duration": 2.902003,
     "end_time": "2022-04-24T15:15:45.119115",
     "exception": false,
     "start_time": "2022-04-24T15:15:42.217112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
      "0    4   8   10   18  25   35   42  56   70    2  63   80    0\n",
      "1    1   3   25   28   3   15   61   7   50    6   6   50   25\n",
      "2    2  21   55   19  24   70   10  10   30    2  13   40   27\n",
      "3    2  12   30   45  12   35    6   8   25    7  28   80    0\n",
      "4    4  11   15   53  12   15    5  20   25   36  48   60   17\n",
      "      d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
      "529     2   4   10   49  12   35   43  11   30    0  26   75    5\n",
      "296     5  48   50   21  65   65    6  47   50   22  51   55    8\n",
      "1052    5  15   15   23  50   50   29  34   35   42  65   65    8\n",
      "691     2  24   70    6  23   60   17  28   70    7  32   80    0\n",
      "863     3  24   45    7  41   75    3  15   25   11  29   50   13\n",
      "9\n",
      "19\n",
      "39\n",
      "79\n",
      "53\n",
      "108\n",
      "40\n",
      "85\n",
      "29\n",
      "59\n",
      "70\n",
      "145\n",
      "63\n",
      "128\n",
      "9\n",
      "19\n",
      "60\n",
      "125\n",
      "65\n",
      "135\n",
      "32\n",
      "67\n",
      "44\n",
      "89\n",
      "14\n",
      "29\n",
      "14\n",
      "29\n",
      "24\n",
      "49\n",
      "22\n",
      "47\n",
      "66\n",
      "136\n",
      "9\n",
      "19\n",
      "54\n",
      "109\n",
      "47\n",
      "97\n",
      "37\n",
      "77\n",
      "38\n",
      "78\n",
      "47\n",
      "97\n",
      "14\n",
      "29\n",
      "18\n",
      "38\n",
      "64\n",
      "134\n",
      "57\n",
      "117\n",
      "29\n",
      "59\n",
      "24\n",
      "49\n",
      "18\n",
      "38\n",
      "63\n",
      "128\n",
      "57\n",
      "117\n",
      "9\n",
      "19\n",
      "69\n",
      "139\n",
      "23\n",
      "48\n",
      "23\n",
      "48\n",
      "47\n",
      "97\n",
      "63\n",
      "128\n",
      "18\n",
      "38\n",
      "44\n",
      "89\n",
      "34\n",
      "69\n",
      "19\n",
      "39\n",
      "28\n",
      "58\n",
      "18\n",
      "38\n",
      "9\n",
      "19\n",
      "47\n",
      "97\n",
      "42\n",
      "87\n",
      "72\n",
      "147\n",
      "63\n",
      "133\n",
      "57\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "STOP_SIGN = \"␣\"   \n",
    "allWorkoutsString = []\n",
    "stringVocab = []\n",
    "\n",
    "#import random\n",
    "\n",
    "\n",
    "##NEW SHUFFLING TO FIX POOR EARLY PERFORMANCE\n",
    "print(df.head())\n",
    "df = df.sample(frac = 1)\n",
    "print(df.head())\n",
    "##NEW SHUFFLING TO FIX POOR EARLY PERFORMANCE\n",
    "\n",
    "for i in range(len(df)):\n",
    "    #df.iloc[i][\"pu\"] = alterRange(df.iloc[i][\"pu\"],df.iloc[i][\"tpu\"]) #right now it overall makes pu way more diffiuclt\n",
    "    workout = (str(df.iloc[i][\"d/l\"]) + \"-DL:~\" + str(df.iloc[i][\"pu\"]) + \"~\" + str(df.iloc[i][\"tpu\"]) + \"~\" + str(df.iloc[i][\"rpu\"]) + \"~\" + str(df.iloc[i][\"su\"]) + \"~\" + str(df.iloc[i][\"tsu\"]) + \"~\" + str(df.iloc[i][\"rsu\"]) + \"~\" + str(df.iloc[i][\"sq\"]) + \"~\" + str(df.iloc[i][\"tsq\"]) + \"~\" + str(df.iloc[i][\"rsq\"]) + \"~\"  +  str(df.iloc[i][\"bp\"]) + \"~\" + str(df.iloc[i][\"tbp\"]) + \"~\" + str(df.iloc[i][\"rbp\"]) + \"~\" + \"␣\" )\n",
    "    #allWorkoutsString.append(workout)\n",
    "    stringVocab.append(workout)\n",
    "      \n",
    "        \n",
    "\n",
    "#df.to_csv(\"./WORKING\")\n",
    "#\n",
    "for z in range(50):   \n",
    "    allWorkoutsString.append(generateExamples(5,True))\n",
    "    #allWorkoutsString.append(generateExamples(4))\n",
    "    #allWorkoutsString.append(generateExamples(3))\n",
    "    #allWorkoutsString.append(generateExamples(2))\n",
    "    #allWorkoutsString.append(generateExamples(1))\n",
    "    \n",
    "#allWorkoutsString.append(generateExamples(5,True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95d9270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:45.218166Z",
     "iopub.status.busy": "2022-04-24T15:15:45.216918Z",
     "iopub.status.idle": "2022-04-24T15:15:45.219318Z",
     "shell.execute_reply": "2022-04-24T15:15:45.219916Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.869946Z"
    },
    "papermill": {
     "duration": 0.048185,
     "end_time": "2022-04-24T15:15:45.220123",
     "exception": false,
     "start_time": "2022-04-24T15:15:45.171938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decodeWorkout(input):    \n",
    "    c = input.split(\"~\")\n",
    "    if(len(c) == 5):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        outputStr = (pushupStr)\n",
    "    elif(len(c) == 8):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr)\n",
    "    elif(len(c)==11):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        squatStr = str(\"\\n\" + c[7] + \" squats for \" + c[8] + \" seconds with \" + c[9] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr + squatStr)\n",
    "    elif(len(c) == 14):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        squatStr = str(\"\\n\" + c[7] + \" squats for \" + c[8] + \" seconds with \" + c[9] + \" second rest \")\n",
    "        burpeeStr = str(\"\\n\" + c[10] + \" burpees for \" + c[11] + \" seconds with \" + c[12] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr + squatStr + burpeeStr)\n",
    "    else:\n",
    "        outputStr = \"fail\"\n",
    "    \n",
    "    return outputStr\n",
    "#for i in range(15) :\n",
    "#        print(decodeWorkout(allWorkoutsString[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54434cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:45.289257Z",
     "iopub.status.busy": "2022-04-24T15:15:45.288534Z",
     "iopub.status.idle": "2022-04-24T15:15:45.299759Z",
     "shell.execute_reply": "2022-04-24T15:15:45.298928Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.886087Z"
    },
    "papermill": {
     "duration": 0.047916,
     "end_time": "2022-04-24T15:15:45.299971",
     "exception": false,
     "start_time": "2022-04-24T15:15:45.252055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_words': None, 'filters': '', 'lower': False, 'split': '', 'char_level': True, 'oov_token': None, 'document_count': 1500, 'word_counts': '{\"5\": 5707, \"-\": 1500, \"D\": 1500, \"L\": 1500, \":\": 1500, \"~\": 19500, \"2\": 4330, \"7\": 1901, \"3\": 3542, \"0\": 4869, \"1\": 4829, \"6\": 2221, \"4\": 3507, \"\\\\u2423\": 1500, \"9\": 1132, \"8\": 1554}', 'word_docs': '{\"5\": 1472, \"~\": 1500, \"L\": 1500, \"0\": 1479, \"1\": 1435, \"6\": 1182, \"-\": 1500, \"3\": 1347, \":\": 1500, \"4\": 1360, \"2\": 1406, \"7\": 1095, \"\\\\u2423\": 1500, \"D\": 1500, \"9\": 835, \"8\": 1005}', 'index_docs': '{\"2\": 1472, \"1\": 1500, \"13\": 1500, \"3\": 1479, \"4\": 1435, \"8\": 1182, \"11\": 1500, \"6\": 1347, \"14\": 1500, \"7\": 1360, \"5\": 1406, \"9\": 1095, \"15\": 1500, \"12\": 1500, \"16\": 835, \"10\": 1005}', 'index_word': '{\"1\": \"~\", \"2\": \"5\", \"3\": \"0\", \"4\": \"1\", \"5\": \"2\", \"6\": \"3\", \"7\": \"4\", \"8\": \"6\", \"9\": \"7\", \"10\": \"8\", \"11\": \"-\", \"12\": \"D\", \"13\": \"L\", \"14\": \":\", \"15\": \"\\\\u2423\", \"16\": \"9\"}', 'word_index': '{\"~\": 1, \"5\": 2, \"0\": 3, \"1\": 4, \"2\": 5, \"3\": 6, \"4\": 7, \"6\": 8, \"7\": 9, \"8\": 10, \"-\": 11, \"D\": 12, \"L\": 13, \":\": 14, \"\\\\u2423\": 15, \"9\": 16}'}\n",
      "Vectorized dataset size 50\n",
      "[[3]]\n",
      "[[4]]\n",
      "[[5]]\n",
      "[[6]]\n",
      "[[7]]\n",
      "[[2]]\n",
      "[[8]]\n",
      "[[9]]\n",
      "[[10]]\n",
      "[[16]]\n"
     ]
    }
   ],
   "source": [
    "#encoding each of the characters into integers so the model can understand -> paying special attention to the stop_sign\n",
    "import pickle\n",
    "\n",
    "with open('../input/lstmfile/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "\n",
    "print(tokenizer.get_config())\n",
    "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1 \n",
    "\n",
    "dataset_vectorized = tokenizer.texts_to_sequences(allWorkoutsString)\n",
    "print('Vectorized dataset size', len(dataset_vectorized))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(tokenizer.texts_to_sequences([f\"{i}\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed375482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:45.372677Z",
     "iopub.status.busy": "2022-04-24T15:15:45.371922Z",
     "iopub.status.idle": "2022-04-24T15:15:45.375896Z",
     "shell.execute_reply": "2022-04-24T15:15:45.376685Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.904907Z"
    },
    "papermill": {
     "duration": 0.043546,
     "end_time": "2022-04-24T15:15:45.376981",
     "exception": false,
     "start_time": "2022-04-24T15:15:45.333435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "#add padding to ensure same length --- only if all are not the sane length\n",
    "print(len(dataset_vectorized))\n",
    "maxLength = 0\n",
    "for workout_index, workout in enumerate(dataset_vectorized[:len(dataset_vectorized)]):\n",
    "    #if(len(workout)) != 167:\n",
    "    if(maxLength < len(workout)):\n",
    "        #print('Workout #{} length: {}'.format(workout_index + 1, len(workout)))\n",
    "        maxLength = len(workout)\n",
    "#padding is required\n",
    "print(maxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f3764ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:45.457464Z",
     "iopub.status.busy": "2022-04-24T15:15:45.456378Z",
     "iopub.status.idle": "2022-04-24T15:15:45.460489Z",
     "shell.execute_reply": "2022-04-24T15:15:45.461380Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.914720Z"
    },
    "papermill": {
     "duration": 0.050498,
     "end_time": "2022-04-24T15:15:45.461614",
     "exception": false,
     "start_time": "2022-04-24T15:15:45.411116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - D L : ~ 1 9 ~ 1 0 ~ 2 2 ~ 5 8 ~ 6 0 ~ 1 4 ~ 6 2 ~ 6 5 ~ 1 ~ 3 1 ~ 3 5 ~ 2 1 ~ ␣\n"
     ]
    }
   ],
   "source": [
    "def decodeVector(vector):\n",
    "    decodedWorkout = tokenizer.sequences_to_texts([vector])[0]\n",
    "    print(decodedWorkout)\n",
    "    \n",
    "#basic test to see if the decoder is working\n",
    "decodeVector(dataset_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f8ba38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:45.548905Z",
     "iopub.status.busy": "2022-04-24T15:15:45.547577Z",
     "iopub.status.idle": "2022-04-24T15:15:45.553118Z",
     "shell.execute_reply": "2022-04-24T15:15:45.552040Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.924476Z"
    },
    "papermill": {
     "duration": 0.052811,
     "end_time": "2022-04-24T15:15:45.553322",
     "exception": false,
     "start_time": "2022-04-24T15:15:45.500511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - D L : ~ 1 9 ~ 1 0 ~ 2 2 ~ 5 8 ~ 6 0 ~ 1 4 ~ 6 2 ~ 6 5 ~ 1 ~ 3 1 ~ 3 5 ~ 2 1 ~ ␣\n"
     ]
    }
   ],
   "source": [
    "dataset_vectorized_padded_without_stops = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    # We use -1 here and +1 in the next step to make sure\n",
    "    # that all recipes will have at least 1 stops sign at the end,\n",
    "    # since each sequence will be shifted and truncated afterwards\n",
    "    # (to generate X and Y sequences).\n",
    "    maxlen=maxLength-1,\n",
    "    #value=tokenizer.texts_to_sequences([STOP_SIGN])[0] #maybe append here again\n",
    ")\n",
    "dataset_vectorized_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized_padded_without_stops,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=maxLength+1,\n",
    "    #value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")\n",
    "\n",
    "for workout_index, workout in enumerate(dataset_vectorized_padded[:len(dataset_vectorized_padded)]):\n",
    "    if(len(workout)) != maxLength+1:\n",
    "        print('Workout #{} length: {}'.format(workout_index + 1, len(workout)))\n",
    "\n",
    "#test it out\n",
    "decodeVector(dataset_vectorized_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f797ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:45.817515Z",
     "iopub.status.busy": "2022-04-24T15:15:45.816419Z",
     "iopub.status.idle": "2022-04-24T15:15:48.513317Z",
     "shell.execute_reply": "2022-04-24T15:15:48.513959Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.938167Z"
    },
    "papermill": {
     "duration": 2.921744,
     "end_time": "2022-04-24T15:15:48.514149",
     "exception": false,
     "start_time": "2022-04-24T15:15:45.592405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 15:15:45.707507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:45.811297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:45.812341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:45.816999: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 15:15:45.818349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:45.819650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:45.820828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:48.178663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:48.179785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:48.180736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 15:15:48.181832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dataset_vectorized_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc0901e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:48.591162Z",
     "iopub.status.busy": "2022-04-24T15:15:48.590478Z",
     "iopub.status.idle": "2022-04-24T15:15:48.668189Z",
     "shell.execute_reply": "2022-04-24T15:15:48.668726Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.948851Z"
    },
    "papermill": {
     "duration": 0.120528,
     "end_time": "2022-04-24T15:15:48.668930",
     "exception": false,
     "start_time": "2022-04-24T15:15:48.548402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((43,), (43,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "#split processing\n",
    "def split_input_target(workout):\n",
    "    input_text = workout[:-1]\n",
    "    target_text = workout[1:]\n",
    "    \n",
    "    return input_text, target_text\n",
    "dataset_targeted = dataset.map(split_input_target)\n",
    "print(dataset_targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e5657ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:48.742999Z",
     "iopub.status.busy": "2022-04-24T15:15:48.741904Z",
     "iopub.status.idle": "2022-04-24T15:15:48.745042Z",
     "shell.execute_reply": "2022-04-24T15:15:48.744497Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.970447Z"
    },
    "papermill": {
     "duration": 0.043517,
     "end_time": "2022-04-24T15:15:48.745188",
     "exception": false,
     "start_time": "2022-04-24T15:15:48.701671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "#compile\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #used to be 0.001 which worked much better\n",
    "\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "792debca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:48.820242Z",
     "iopub.status.busy": "2022-04-24T15:15:48.819200Z",
     "iopub.status.idle": "2022-04-24T15:15:48.897720Z",
     "shell.execute_reply": "2022-04-24T15:15:48.897129Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.978841Z"
    },
    "papermill": {
     "duration": 0.118153,
     "end_time": "2022-04-24T15:15:48.897895",
     "exception": false,
     "start_time": "2022-04-24T15:15:48.779742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a checkpoints directory. TO SAVE AND CONTINUE TRAINING\n",
    "checkpoint_dir = 'tmp/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_') #used to be ckpt_{epoch}, got rid due to space issues on kaggle\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37081a05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:48.974510Z",
     "iopub.status.busy": "2022-04-24T15:15:48.973880Z",
     "iopub.status.idle": "2022-04-24T15:15:49.638518Z",
     "shell.execute_reply": "2022-04-24T15:15:49.637460Z",
     "shell.execute_reply.started": "2022-04-24T15:14:26.989061Z"
    },
    "papermill": {
     "duration": 0.705091,
     "end_time": "2022-04-24T15:15:49.638719",
     "exception": false,
     "start_time": "2022-04-24T15:15:48.933628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "#model = keras.models.load_model(\n",
    "#    \"../input/lstmfile/baselineModel.h5\", custom_objects={\"loss\": loss}\n",
    "#)\n",
    "\n",
    "\n",
    "model = keras.models.load_model(\"../input/lstmfile/simplified_model.h5\")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=loss\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "536a483d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:49.713193Z",
     "iopub.status.busy": "2022-04-24T15:15:49.712254Z",
     "iopub.status.idle": "2022-04-24T15:15:49.723071Z",
     "shell.execute_reply": "2022-04-24T15:15:49.723858Z",
     "shell.execute_reply.started": "2022-04-24T15:14:27.791716Z"
    },
    "papermill": {
     "duration": 0.050462,
     "end_time": "2022-04-24T15:15:49.724102",
     "exception": false,
     "start_time": "2022-04-24T15:15:49.673640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((1, 43), (1, 43)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# Batch size.\n",
    "BATCH_SIZE = 1\n",
    "# Buffer size to shuffle the dataset (TF data is designed to work\n",
    "# with possibly infinite sequences, so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in\n",
    "# which it shuffles elements).\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "dataset_train = dataset_targeted \\\n",
    "  .shuffle(SHUFFLE_BUFFER_SIZE) \\\n",
    "  .batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "  .repeat()\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5313f822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:49.799133Z",
     "iopub.status.busy": "2022-04-24T15:15:49.798259Z",
     "iopub.status.idle": "2022-04-24T15:15:49.806305Z",
     "shell.execute_reply": "2022-04-24T15:15:49.805435Z",
     "shell.execute_reply.started": "2022-04-24T15:14:27.802202Z"
    },
    "papermill": {
     "duration": 0.047504,
     "end_time": "2022-04-24T15:15:49.806484",
     "exception": false,
     "start_time": "2022-04-24T15:15:49.758980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:           3\n",
      "INITIAL_EPOCH:    1\n",
      "STEPS_PER_EPOCH:  1\n"
     ]
    }
   ],
   "source": [
    "#const\n",
    "EPOCHS = 3 #5 seemed to work well\n",
    "INITIAL_EPOCH = 1\n",
    "STEPS_PER_EPOCH = 1  #len(allWorkoutsString) / BATCH_SIZE\n",
    "print('EPOCHS:          ', EPOCHS) \n",
    "print('INITIAL_EPOCH:   ', INITIAL_EPOCH)\n",
    "print('STEPS_PER_EPOCH: ', STEPS_PER_EPOCH) #default was 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dceed36f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:49.882477Z",
     "iopub.status.busy": "2022-04-24T15:15:49.881422Z",
     "iopub.status.idle": "2022-04-24T15:15:54.107538Z",
     "shell.execute_reply": "2022-04-24T15:15:54.106973Z",
     "shell.execute_reply.started": "2022-04-24T15:14:27.811670Z"
    },
    "papermill": {
     "duration": 4.266877,
     "end_time": "2022-04-24T15:15:54.107760",
     "exception": false,
     "start_time": "2022-04-24T15:15:49.840883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 15:15:51.251794: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-24 15:15:52.381070: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 3.0219\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8770\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=dataset_train,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        #tqdm_callback\n",
    "       # early_stopping_callback #we want to overfit this so get rid of early stopping\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7950a11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:54.196814Z",
     "iopub.status.busy": "2022-04-24T15:15:54.194569Z",
     "iopub.status.idle": "2022-04-24T15:15:54.197570Z",
     "shell.execute_reply": "2022-04-24T15:15:54.198154Z",
     "shell.execute_reply.started": "2022-04-24T15:14:29.223461Z"
    },
    "papermill": {
     "duration": 0.051159,
     "end_time": "2022-04-24T15:15:54.198317",
     "exception": false,
     "start_time": "2022-04-24T15:15:54.147158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate = 1000, temperature=1.0):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    padded_start_string = start_string\n",
    "    # Converting our start string to numbers (vectorizing).\n",
    "    input_indices = np.array(tokenizer.texts_to_sequences([padded_start_string]))\n",
    "    # Empty string to store our results.\n",
    "    text_generated = []\n",
    "    # Here batch size == 1.\n",
    "   # model.reset_states()\n",
    "    for char_index in range(num_generate):\n",
    "        predictions = model(input_indices)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # Using a categorical distribution to predict the character returned by the model.\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions,\n",
    "            num_samples=1\n",
    "        )[-1, 0].numpy()\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state.\n",
    "        input_indices = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        next_character = tokenizer.sequences_to_texts(input_indices.numpy())[0]\n",
    "        text_generated.append(next_character)\n",
    "\n",
    "       # output = ''.join(text_generated)\n",
    "\n",
    "       # output = decodeWorkout(output)\n",
    "\n",
    "    return (padded_start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecd566ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:54.287062Z",
     "iopub.status.busy": "2022-04-24T15:15:54.281097Z",
     "iopub.status.idle": "2022-04-24T15:15:54.725686Z",
     "shell.execute_reply": "2022-04-24T15:15:54.724616Z",
     "shell.execute_reply.started": "2022-04-24T15:14:29.232919Z"
    },
    "papermill": {
     "duration": 0.486716,
     "end_time": "2022-04-24T15:15:54.725888",
     "exception": false,
     "start_time": "2022-04-24T15:15:54.239172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vocab_size=VOCABULARY_SIZE\n",
    "#embedding_dim=256\n",
    "#rnn_units=1024\n",
    "#\n",
    "#simplified_batch_size = 1\n",
    "#model_simplified = build_model(vocab_size, embedding_dim, rnn_units, simplified_batch_size)\n",
    "#model_simplified.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "#model_simplified.build(tf.TensorShape([simplified_batch_size, None]))\n",
    "#model_simplified.summary()\n",
    "\n",
    "nonTrainedModel = keras.models.load_model(\"../input/lstmfile/simplified_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca96c803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:54.808802Z",
     "iopub.status.busy": "2022-04-24T15:15:54.807688Z",
     "iopub.status.idle": "2022-04-24T15:15:55.108939Z",
     "shell.execute_reply": "2022-04-24T15:15:55.109829Z",
     "shell.execute_reply.started": "2022-04-24T15:14:48.272823Z"
    },
    "papermill": {
     "duration": 0.34526,
     "end_time": "2022-04-24T15:15:55.110106",
     "exception": false,
     "start_time": "2022-04-24T15:15:54.764846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-DL:~20~20~52~61~65~14~56~60~11~59~60~11~65~60~\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '5-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))\n",
    "\n",
    "#allWorkoutsString.append(\"5-DL:~60~50~28~14~15~17~15~15~36~34~35~5~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~40~30~6~10~10~5~44~45~6~41~45~16~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~75~65~9~24~25~45~41~45~34~72~80~0~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~85~70~0~55~55~3~33~35~23~30~30~34~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~60~50~22~68~75~4~63~70~6~14~15~33~␣\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bccde7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:55.194206Z",
     "iopub.status.busy": "2022-04-24T15:15:55.192384Z",
     "iopub.status.idle": "2022-04-24T15:15:55.491539Z",
     "shell.execute_reply": "2022-04-24T15:15:55.492638Z",
     "shell.execute_reply.started": "2022-04-24T15:14:29.796878Z"
    },
    "papermill": {
     "duration": 0.343321,
     "end_time": "2022-04-24T15:15:55.492901",
     "exception": false,
     "start_time": "2022-04-24T15:15:55.149580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-DL:~␣\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '4-DL:', num_generate = 43, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe0314a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:55.575939Z",
     "iopub.status.busy": "2022-04-24T15:15:55.574865Z",
     "iopub.status.idle": "2022-04-24T15:15:55.869283Z",
     "shell.execute_reply": "2022-04-24T15:15:55.869875Z",
     "shell.execute_reply.started": "2022-04-24T15:14:29.995087Z"
    },
    "papermill": {
     "duration": 0.33844,
     "end_time": "2022-04-24T15:15:55.870062",
     "exception": false,
     "start_time": "2022-04-24T15:15:55.531622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-DL:~15~25~31~31~55~16~9~15~25~18~30~11~13~25~1\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '3-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9a2a0f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:55.962653Z",
     "iopub.status.busy": "2022-04-24T15:15:55.959711Z",
     "iopub.status.idle": "2022-04-24T15:15:56.260729Z",
     "shell.execute_reply": "2022-04-24T15:15:56.259913Z",
     "shell.execute_reply.started": "2022-04-24T15:14:30.197145Z"
    },
    "papermill": {
     "duration": 0.34756,
     "end_time": "2022-04-24T15:15:56.260875",
     "exception": false,
     "start_time": "2022-04-24T15:15:55.913315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-DL:~60~2~␣\n",
      "fail\n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '2-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29ae4acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:56.389033Z",
     "iopub.status.busy": "2022-04-24T15:15:56.387935Z",
     "iopub.status.idle": "2022-04-24T15:15:56.686210Z",
     "shell.execute_reply": "2022-04-24T15:15:56.685594Z",
     "shell.execute_reply.started": "2022-04-24T15:14:30.414942Z"
    },
    "papermill": {
     "duration": 0.380961,
     "end_time": "2022-04-24T15:15:56.686358",
     "exception": false,
     "start_time": "2022-04-24T15:15:56.305397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-DL:~4~20~19~6~40~13~9~55~15~9~45~12~␣\n",
      "1-DL:\n",
      "4 pushups for 20 seconds with 19 second rest \n",
      "6 situps for 40 seconds with 13 second rest \n",
      "9 squats for 55 seconds with 15 second rest \n",
      "9 burpees for 45 seconds with 12 second rest \n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model, '1-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b028b85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T15:15:56.770011Z",
     "iopub.status.busy": "2022-04-24T15:15:56.769186Z",
     "iopub.status.idle": "2022-04-24T15:15:56.773640Z",
     "shell.execute_reply": "2022-04-24T15:15:56.773105Z",
     "shell.execute_reply.started": "2022-04-24T15:14:30.633493Z"
    },
    "papermill": {
     "duration": 0.047843,
     "end_time": "2022-04-24T15:15:56.773827",
     "exception": false,
     "start_time": "2022-04-24T15:15:56.725984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"demofile2.txt\", \"a\")\n",
    "f.write(\"Now the file has more content!\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.684354,
   "end_time": "2022-04-24T15:16:00.234893",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-24T15:15:25.550539",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
