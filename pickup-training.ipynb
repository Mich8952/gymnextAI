{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1171d1e2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:45.611209Z",
     "iopub.status.busy": "2022-04-24T22:36:45.610360Z",
     "iopub.status.idle": "2022-04-24T22:36:45.629985Z",
     "shell.execute_reply": "2022-04-24T22:36:45.630578Z",
     "shell.execute_reply.started": "2022-04-24T22:34:52.353005Z"
    },
    "papermill": {
     "duration": 0.054432,
     "end_time": "2022-04-24T22:36:45.630860",
     "exception": false,
     "start_time": "2022-04-24T22:36:45.576428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n",
      "[GCC 9.4.0]\n",
      "/kaggle/input/lstmfile/ckpt_.data-00000-of-00001\n",
      "/kaggle/input/lstmfile/LSTM.tflite\n",
      "/kaggle/input/lstmfile/tokenizer.pickle\n",
      "/kaggle/input/lstmfile/ckpt_.index\n",
      "/kaggle/input/lstmfile/simplified_model.h5\n",
      "/kaggle/input/lstmfile/baselineModel.h5\n",
      "/kaggle/input/lstmfile/checkpoint\n",
      "/kaggle/input/newencoded/encodedNew.csv\n",
      "/kaggle/input/recursivebasefile1/encodedNew.csv\n",
      "/kaggle/input/recursivebasefile1/tokenizer.pickle\n",
      "/kaggle/input/recursivebasefile1/baselineModel.h5\n",
      "/kaggle/input ['lstmfile', 'newencoded', 'recursivebasefile1']\n",
      "/kaggle/input/lstmfile []\n",
      "/kaggle/input/newencoded []\n",
      "/kaggle/input/recursivebasefile1 []\n"
     ]
    }
   ],
   "source": [
    "#!pip list\n",
    "\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "count = 0\n",
    "for root, folders, filenames in os.walk('/kaggle/input'):\n",
    "   print(root, folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d93584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:45.711974Z",
     "iopub.status.busy": "2022-04-24T22:36:45.711128Z",
     "iopub.status.idle": "2022-04-24T22:36:45.713722Z",
     "shell.execute_reply": "2022-04-24T22:36:45.714249Z",
     "shell.execute_reply.started": "2022-04-24T22:34:52.378970Z"
    },
    "papermill": {
     "duration": 0.041412,
     "end_time": "2022-04-24T22:36:45.714448",
     "exception": false,
     "start_time": "2022-04-24T22:36:45.673036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        units=rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True, #look into this causing the issue potentially, originally was True\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal() #used to be be tf.keras.initializers.GlorotNormal() before downgradingf\n",
    "    )) # temp removed\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a291ae17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:45.777134Z",
     "iopub.status.busy": "2022-04-24T22:36:45.776609Z",
     "iopub.status.idle": "2022-04-24T22:36:51.158730Z",
     "shell.execute_reply": "2022-04-24T22:36:51.159374Z",
     "shell.execute_reply.started": "2022-04-24T22:34:52.387235Z"
    },
    "papermill": {
     "duration": 5.415736,
     "end_time": "2022-04-24T22:36:51.159597",
     "exception": false,
     "start_time": "2022-04-24T22:36:45.743861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf # ML/DL\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "import tensorflow_addons as tfa\n",
    "#import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3e6237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:51.234738Z",
     "iopub.status.busy": "2022-04-24T22:36:51.233888Z",
     "iopub.status.idle": "2022-04-24T22:36:51.268608Z",
     "shell.execute_reply": "2022-04-24T22:36:51.267990Z",
     "shell.execute_reply.started": "2022-04-24T22:34:54.217167Z"
    },
    "papermill": {
     "duration": 0.074233,
     "end_time": "2022-04-24T22:36:51.268763",
     "exception": false,
     "start_time": "2022-04-24T22:36:51.194530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d/l</th>\n",
       "      <th>pu</th>\n",
       "      <th>tpu</th>\n",
       "      <th>rpu</th>\n",
       "      <th>su</th>\n",
       "      <th>tsu</th>\n",
       "      <th>rsu</th>\n",
       "      <th>sq</th>\n",
       "      <th>tsq</th>\n",
       "      <th>rsq</th>\n",
       "      <th>bp</th>\n",
       "      <th>tbp</th>\n",
       "      <th>rbp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>53</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
       "0    4   8   10   18  25   35   42  56   70    2  63   80    0\n",
       "1    1   3   25   28   3   15   61   7   50    6   6   50   25\n",
       "2    2  21   55   19  24   70   10  10   30    2  13   40   27\n",
       "3    2  12   30   45  12   35    6   8   25    7  28   80    0\n",
       "4    4  11   15   53  12   15    5  20   25   36  48   60   17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try: #for recursive model training\n",
    "#    df = pd.read_csv(os.path.join('./WORKING'))\n",
    "#    print('Wokrgin')\n",
    "#except:\n",
    "df = pd.read_csv(os.path.join('../input/recursivebasefile1/encodedNew.csv'))\n",
    "#OG DATAFRAME\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d568f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:51.348201Z",
     "iopub.status.busy": "2022-04-24T22:36:51.347363Z",
     "iopub.status.idle": "2022-04-24T22:36:51.383349Z",
     "shell.execute_reply": "2022-04-24T22:36:51.384366Z",
     "shell.execute_reply.started": "2022-04-24T22:34:54.244301Z"
    },
    "papermill": {
     "duration": 0.080053,
     "end_time": "2022-04-24T22:36:51.384540",
     "exception": false,
     "start_time": "2022-04-24T22:36:51.304487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def alterRange(pu,tpu): #THE MODEL DOESNT CONTAIN ALL THE VOCAB WE ARE ASKING IT TO, EITHER MAP TO CLOSEST VOCAB OR RETAIN THE MOBEL ON MORE POSSIBLE NUMBER\n",
    "    mul = pu/tpu\n",
    "    alterMul = mul + 1.0 #should be 0.03 but ill make it 0.5 for now\n",
    "    pu = alterMul * tpu  \n",
    "    return int(float(pu))\n",
    "\n",
    "\n",
    "def generateAction(diffLevel):\n",
    "    if diffLevel == 5: \n",
    "        multiplier = random.uniform(0.9,1)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 4: \n",
    "        multiplier = random.uniform(0.7,0.8)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 3: \n",
    "        multiplier = random.uniform(0.5,0.6)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 2: \n",
    "        multiplier = random.uniform(0.3,0.4)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    elif diffLevel == 1: \n",
    "        multiplier = random.uniform(0.1,0.2)\n",
    "        tpa = random.randrange(10,80,5)\n",
    "        numActions = int(tpa * multiplier)\n",
    "        rpa = random.randrange(0,80-int(tpa))\n",
    "    return tpa,numActions,rpa\n",
    "\n",
    "def generateExamples(diffLevel, alter=False):\n",
    "    if diffLevel == 5: \n",
    "        tpu,pu,rpu = generateAction(5)\n",
    "        tsu,su,rsu = generateAction(5)\n",
    "        tsq,sq,rsq = generateAction(5)\n",
    "        tbp,bp,rbp = generateAction(5)\n",
    "        print(pu)\n",
    "        #temp\n",
    "        if(alter == True):\n",
    "            pu = alterRange(pu,tpu)\n",
    "        #temp\n",
    "        print(pu)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "        #outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 4: \n",
    "        tpu,pu,rpu = generateAction(4)\n",
    "        tsu,su,rsu = generateAction(4)\n",
    "        tsq,sq,rsq = generateAction(4)\n",
    "        tbp,bp,rbp = generateAction(4)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 3: \n",
    "        tpu,pu,rpu = generateAction(3)\n",
    "        tsu,su,rsu = generateAction(3)\n",
    "        tsq,sq,rsq = generateAction(3)\n",
    "        tbp,bp,rbp = generateAction(3)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 2: \n",
    "        tpu,pu,rpu = generateAction(2)\n",
    "        tsu,su,rsu = generateAction(2)\n",
    "        tsq,sq,rsq = generateAction(2)\n",
    "        tbp,bp,rbp = generateAction(2)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    elif diffLevel == 1: \n",
    "        tpu,pu,rpu = generateAction(1)\n",
    "        tsu,su,rsu = generateAction(1)\n",
    "        tsq,sq,rsq = generateAction(1)\n",
    "        tbp,bp,rbp = generateAction(1)\n",
    "        outputStr = (str(diffLevel) + \"-DL:~\" + str(pu) + \"~\" + str(tpu) + \"~\" + str(rpu) + \"~\" + str(su) + \"~\" + str(tsu) + \"~\" + str(rsu) + \"~\" + str(sq) + \"~\" + str(tsq) + \"~\" + str(rsq) + \"~\"  +  str(bp) + \"~\" + str(tbp) + \"~\" + str(rbp) + \"~\" + \"␣\" )\n",
    "    return outputStr\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c99b0f1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:51.463252Z",
     "iopub.status.busy": "2022-04-24T22:36:51.462483Z",
     "iopub.status.idle": "2022-04-24T22:36:53.205768Z",
     "shell.execute_reply": "2022-04-24T22:36:53.205151Z",
     "shell.execute_reply.started": "2022-04-24T22:36:12.401609Z"
    },
    "papermill": {
     "duration": 1.78559,
     "end_time": "2022-04-24T22:36:53.205936",
     "exception": false,
     "start_time": "2022-04-24T22:36:51.420346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
      "0    4   8   10   18  25   35   42  56   70    2  63   80    0\n",
      "1    1   3   25   28   3   15   61   7   50    6   6   50   25\n",
      "2    2  21   55   19  24   70   10  10   30    2  13   40   27\n",
      "3    2  12   30   45  12   35    6   8   25    7  28   80    0\n",
      "4    4  11   15   53  12   15    5  20   25   36  48   60   17\n",
      "      d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
      "417     1   9   60    4   5   25   49   3   15   13   8   50   25\n",
      "1003    1  11   80    0   2   10   16   8   45    3   8   50    5\n",
      "905     1   7   60    6   3   20   60  10   50   15   4   20   12\n",
      "789     1   2   10   23  12   75    4   9   45   34  10   55   18\n",
      "1098    5  23   25    0  43   45    6  34   35   35  58   60   19\n",
      "      d/l  pu  tpu  rpu  su  tsu  rsu  sq  tsq  rsq  bp  tbp  rbp\n",
      "417     1  69   60    4   5   25   49   3   15   13   8   50   25\n",
      "1003    1  91   80    0   2   10   16   8   45    3   8   50    5\n",
      "905     1  67   60    6   3   20   60  10   50   15   4   20   12\n",
      "789     1  12   10   23  12   75    4   9   45   34  10   55   18\n",
      "1098    5  48   25    0  43   45    6  34   35   35  58   60   19\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path  \n",
    "STOP_SIGN = \"␣\"   \n",
    "allWorkoutsString = []\n",
    "stringVocab = []\n",
    "\n",
    "#import random\n",
    "\n",
    "\n",
    "##NEW SHUFFLING TO FIX POOR EARLY PERFORMANCE\n",
    "print(df.head())\n",
    "df = df.sample(frac = 1)\n",
    "print(df.head())\n",
    "##NEW SHUFFLING TO FIX POOR EARLY PERFORMANCE\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df.iloc[i][\"pu\"] = alterRange(df.iloc[i][\"pu\"],df.iloc[i][\"tpu\"]) #right now it overall makes pu way more diffiuclt\n",
    "    workout = (str(df.iloc[i][\"d/l\"]) + \"-DL:~\" + str(df.iloc[i][\"pu\"]) + \"~\" + str(df.iloc[i][\"tpu\"]) + \"~\" + str(df.iloc[i][\"rpu\"]) + \"~\" + str(df.iloc[i][\"su\"]) + \"~\" + str(df.iloc[i][\"tsu\"]) + \"~\" + str(df.iloc[i][\"rsu\"]) + \"~\" + str(df.iloc[i][\"sq\"]) + \"~\" + str(df.iloc[i][\"tsq\"]) + \"~\" + str(df.iloc[i][\"rsq\"]) + \"~\"  +  str(df.iloc[i][\"bp\"]) + \"~\" + str(df.iloc[i][\"tbp\"]) + \"~\" + str(df.iloc[i][\"rbp\"]) + \"~\" + \"␣\" )\n",
    "    allWorkoutsString.append(workout)\n",
    "    #stringVocab.append(workout)\n",
    "      \n",
    "print(df.head())    \n",
    "\n",
    "filepath = Path('new/encodedNew.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    \n",
    "df.to_csv(filepath)\n",
    "#\n",
    "#for z in range(50):   \n",
    "    #allWorkoutsString.append(generateExamples(5,True))\n",
    "    #allWorkoutsString.append(generateExamples(4))\n",
    "    #allWorkoutsString.append(generateExamples(3))\n",
    "    #allWorkoutsString.append(generateExamples(2))\n",
    "    #allWorkoutsString.append(generateExamples(1))\n",
    "    \n",
    "#allWorkoutsString.append(generateExamples(5,True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680718a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:53.263290Z",
     "iopub.status.busy": "2022-04-24T22:36:53.262543Z",
     "iopub.status.idle": "2022-04-24T22:36:53.264542Z",
     "shell.execute_reply": "2022-04-24T22:36:53.264940Z"
    },
    "papermill": {
     "duration": 0.035521,
     "end_time": "2022-04-24T22:36:53.265055",
     "exception": false,
     "start_time": "2022-04-24T22:36:53.229534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decodeWorkout(input):    \n",
    "    c = input.split(\"~\")\n",
    "    if(len(c) == 5):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        outputStr = (pushupStr)\n",
    "    elif(len(c) == 8):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr)\n",
    "    elif(len(c)==11):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        squatStr = str(\"\\n\" + c[7] + \" squats for \" + c[8] + \" seconds with \" + c[9] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr + squatStr)\n",
    "    elif(len(c) == 14):\n",
    "        pushupStr = str(c[0] + \"\\n\" + c[1] + \" pushups for \" + c[2] + \" seconds with \" + c[3] + \" second rest \")\n",
    "        situpStr = str(\"\\n\" + c[4] + \" situps for \" + c[5] + \" seconds with \" + c[6] + \" second rest \")\n",
    "        squatStr = str(\"\\n\" + c[7] + \" squats for \" + c[8] + \" seconds with \" + c[9] + \" second rest \")\n",
    "        burpeeStr = str(\"\\n\" + c[10] + \" burpees for \" + c[11] + \" seconds with \" + c[12] + \" second rest \")\n",
    "        outputStr = (pushupStr + situpStr + squatStr + burpeeStr)\n",
    "    else:\n",
    "        outputStr = \"fail\"\n",
    "    \n",
    "    return outputStr\n",
    "#for i in range(15) :\n",
    "#        print(decodeWorkout(allWorkoutsString[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901fc679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:53.314691Z",
     "iopub.status.busy": "2022-04-24T22:36:53.314129Z",
     "iopub.status.idle": "2022-04-24T22:36:53.337443Z",
     "shell.execute_reply": "2022-04-24T22:36:53.337970Z"
    },
    "papermill": {
     "duration": 0.050777,
     "end_time": "2022-04-24T22:36:53.338128",
     "exception": false,
     "start_time": "2022-04-24T22:36:53.287351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_words': None, 'filters': '', 'lower': False, 'split': '', 'char_level': True, 'oov_token': None, 'document_count': 1500, 'word_counts': '{\"5\": 5707, \"-\": 1500, \"D\": 1500, \"L\": 1500, \":\": 1500, \"~\": 19500, \"2\": 4330, \"7\": 1901, \"3\": 3542, \"0\": 4869, \"1\": 4829, \"6\": 2221, \"4\": 3507, \"\\\\u2423\": 1500, \"9\": 1132, \"8\": 1554}', 'word_docs': '{\"5\": 1472, \"~\": 1500, \"L\": 1500, \"0\": 1479, \"1\": 1435, \"6\": 1182, \"-\": 1500, \"3\": 1347, \":\": 1500, \"4\": 1360, \"2\": 1406, \"7\": 1095, \"\\\\u2423\": 1500, \"D\": 1500, \"9\": 835, \"8\": 1005}', 'index_docs': '{\"2\": 1472, \"1\": 1500, \"13\": 1500, \"3\": 1479, \"4\": 1435, \"8\": 1182, \"11\": 1500, \"6\": 1347, \"14\": 1500, \"7\": 1360, \"5\": 1406, \"9\": 1095, \"15\": 1500, \"12\": 1500, \"16\": 835, \"10\": 1005}', 'index_word': '{\"1\": \"~\", \"2\": \"5\", \"3\": \"0\", \"4\": \"1\", \"5\": \"2\", \"6\": \"3\", \"7\": \"4\", \"8\": \"6\", \"9\": \"7\", \"10\": \"8\", \"11\": \"-\", \"12\": \"D\", \"13\": \"L\", \"14\": \":\", \"15\": \"\\\\u2423\", \"16\": \"9\"}', 'word_index': '{\"~\": 1, \"5\": 2, \"0\": 3, \"1\": 4, \"2\": 5, \"3\": 6, \"4\": 7, \"6\": 8, \"7\": 9, \"8\": 10, \"-\": 11, \"D\": 12, \"L\": 13, \":\": 14, \"\\\\u2423\": 15, \"9\": 16}'}\n",
      "Vectorized dataset size 1500\n",
      "[[3]]\n",
      "[[4]]\n",
      "[[5]]\n",
      "[[6]]\n",
      "[[7]]\n",
      "[[2]]\n",
      "[[8]]\n",
      "[[9]]\n",
      "[[10]]\n",
      "[[16]]\n"
     ]
    }
   ],
   "source": [
    "#encoding each of the characters into integers so the model can understand -> paying special attention to the stop_sign\n",
    "import pickle\n",
    "\n",
    "with open('../input/lstmfile/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "\n",
    "print(tokenizer.get_config())\n",
    "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1 \n",
    "\n",
    "dataset_vectorized = tokenizer.texts_to_sequences(allWorkoutsString)\n",
    "print('Vectorized dataset size', len(dataset_vectorized))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(tokenizer.texts_to_sequences([f\"{i}\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df9b5cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:53.390277Z",
     "iopub.status.busy": "2022-04-24T22:36:53.389671Z",
     "iopub.status.idle": "2022-04-24T22:36:53.392624Z",
     "shell.execute_reply": "2022-04-24T22:36:53.393206Z"
    },
    "papermill": {
     "duration": 0.031845,
     "end_time": "2022-04-24T22:36:53.393381",
     "exception": false,
     "start_time": "2022-04-24T22:36:53.361536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "#add padding to ensure same length --- only if all are not the sane length\n",
    "print(len(dataset_vectorized))\n",
    "maxLength = 0\n",
    "for workout_index, workout in enumerate(dataset_vectorized[:len(dataset_vectorized)]):\n",
    "    #if(len(workout)) != 167:\n",
    "    if(maxLength < len(workout)):\n",
    "        #print('Workout #{} length: {}'.format(workout_index + 1, len(workout)))\n",
    "        maxLength = len(workout)\n",
    "#padding is required\n",
    "print(maxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3d18e9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:53.445797Z",
     "iopub.status.busy": "2022-04-24T22:36:53.445226Z",
     "iopub.status.idle": "2022-04-24T22:36:53.448757Z",
     "shell.execute_reply": "2022-04-24T22:36:53.447979Z"
    },
    "papermill": {
     "duration": 0.031044,
     "end_time": "2022-04-24T22:36:53.448899",
     "exception": false,
     "start_time": "2022-04-24T22:36:53.417855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - D L : ~ 6 9 ~ 6 0 ~ 4 ~ 5 ~ 2 5 ~ 4 9 ~ 3 ~ 1 5 ~ 1 3 ~ 8 ~ 5 0 ~ 2 5 ~ ␣\n"
     ]
    }
   ],
   "source": [
    "def decodeVector(vector):\n",
    "    decodedWorkout = tokenizer.sequences_to_texts([vector])[0]\n",
    "    print(decodedWorkout)\n",
    "    \n",
    "#basic test to see if the decoder is working\n",
    "decodeVector(dataset_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8551f89a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:53.527600Z",
     "iopub.status.busy": "2022-04-24T22:36:53.504709Z",
     "iopub.status.idle": "2022-04-24T22:36:53.538125Z",
     "shell.execute_reply": "2022-04-24T22:36:53.537533Z"
    },
    "papermill": {
     "duration": 0.063007,
     "end_time": "2022-04-24T22:36:53.538258",
     "exception": false,
     "start_time": "2022-04-24T22:36:53.475251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - D L : ~ 6 9 ~ 6 0 ~ 4 ~ 5 ~ 2 5 ~ 4 9 ~ 3 ~ 1 5 ~ 1 3 ~ 8 ~ 5 0 ~ 2 5 ~ ␣\n"
     ]
    }
   ],
   "source": [
    "dataset_vectorized_padded_without_stops = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    # We use -1 here and +1 in the next step to make sure\n",
    "    # that all recipes will have at least 1 stops sign at the end,\n",
    "    # since each sequence will be shifted and truncated afterwards\n",
    "    # (to generate X and Y sequences).\n",
    "    maxlen=maxLength-1,\n",
    "    #value=tokenizer.texts_to_sequences([STOP_SIGN])[0] #maybe append here again\n",
    ")\n",
    "dataset_vectorized_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized_padded_without_stops,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=maxLength+1,\n",
    "    #value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")\n",
    "\n",
    "for workout_index, workout in enumerate(dataset_vectorized_padded[:len(dataset_vectorized_padded)]):\n",
    "    if(len(workout)) != maxLength+1:\n",
    "        print('Workout #{} length: {}'.format(workout_index + 1, len(workout)))\n",
    "\n",
    "#test it out\n",
    "decodeVector(dataset_vectorized_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2feb7d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:55.805358Z",
     "iopub.status.busy": "2022-04-24T22:36:53.590796Z",
     "iopub.status.idle": "2022-04-24T22:36:55.813933Z",
     "shell.execute_reply": "2022-04-24T22:36:55.814361Z"
    },
    "papermill": {
     "duration": 2.251657,
     "end_time": "2022-04-24T22:36:55.814556",
     "exception": false,
     "start_time": "2022-04-24T22:36:53.562899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:36:53.655297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:53.751131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:53.751917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:53.754254: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-24 22:36:53.755597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:53.756254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:53.756906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:55.507258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:55.508119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:55.508765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-24 22:36:55.509353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dataset_vectorized_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34dcb3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:55.871452Z",
     "iopub.status.busy": "2022-04-24T22:36:55.870854Z",
     "iopub.status.idle": "2022-04-24T22:36:55.937775Z",
     "shell.execute_reply": "2022-04-24T22:36:55.937183Z"
    },
    "papermill": {
     "duration": 0.097755,
     "end_time": "2022-04-24T22:36:55.937923",
     "exception": false,
     "start_time": "2022-04-24T22:36:55.840168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((44,), (44,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "#split processing\n",
    "def split_input_target(workout):\n",
    "    input_text = workout[:-1]\n",
    "    target_text = workout[1:]\n",
    "    \n",
    "    return input_text, target_text\n",
    "dataset_targeted = dataset.map(split_input_target)\n",
    "print(dataset_targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21024bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:55.996879Z",
     "iopub.status.busy": "2022-04-24T22:36:55.996258Z",
     "iopub.status.idle": "2022-04-24T22:36:55.998944Z",
     "shell.execute_reply": "2022-04-24T22:36:55.998545Z"
    },
    "papermill": {
     "duration": 0.033761,
     "end_time": "2022-04-24T22:36:55.999045",
     "exception": false,
     "start_time": "2022-04-24T22:36:55.965284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "#compile\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #used to be 0.001 which worked much better\n",
    "\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b6c41f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:56.055479Z",
     "iopub.status.busy": "2022-04-24T22:36:56.054893Z",
     "iopub.status.idle": "2022-04-24T22:36:56.112708Z",
     "shell.execute_reply": "2022-04-24T22:36:56.112234Z"
    },
    "papermill": {
     "duration": 0.088373,
     "end_time": "2022-04-24T22:36:56.112817",
     "exception": false,
     "start_time": "2022-04-24T22:36:56.024444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a checkpoints directory. TO SAVE AND CONTINUE TRAINING\n",
    "checkpoint_dir = 'tmp/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_') #used to be ckpt_{epoch}, got rid due to space issues on kaggle\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7ec3d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:56.169029Z",
     "iopub.status.busy": "2022-04-24T22:36:56.165487Z",
     "iopub.status.idle": "2022-04-24T22:36:57.112164Z",
     "shell.execute_reply": "2022-04-24T22:36:57.112654Z"
    },
    "papermill": {
     "duration": 0.974507,
     "end_time": "2022-04-24T22:36:57.112815",
     "exception": false,
     "start_time": "2022-04-24T22:36:56.138308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "#OG MODEL\n",
    "#model = keras.models.load_model(\n",
    "#    \"../input/lstmfile/baselineModel.h5\", custom_objects={\"loss\": loss}\n",
    "#)\n",
    "\n",
    "\n",
    "#New recursive approach\n",
    "model = keras.models.load_model(\n",
    "    \"../input/recursivebasefile1/baselineModel.h5\", custom_objects={\"loss\": loss}\n",
    ")\n",
    "\n",
    "\n",
    "#model = keras.models.load_model(\"../input/lstmfile/baselineModel.h5\")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=loss\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82bcb64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:57.170068Z",
     "iopub.status.busy": "2022-04-24T22:36:57.169369Z",
     "iopub.status.idle": "2022-04-24T22:36:57.179241Z",
     "shell.execute_reply": "2022-04-24T22:36:57.178813Z"
    },
    "papermill": {
     "duration": 0.039972,
     "end_time": "2022-04-24T22:36:57.179375",
     "exception": false,
     "start_time": "2022-04-24T22:36:57.139403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((64, 44), (64, 44)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# Batch size.\n",
    "BATCH_SIZE = 64\n",
    "# Buffer size to shuffle the dataset (TF data is designed to work\n",
    "# with possibly infinite sequences, so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in\n",
    "# which it shuffles elements).\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "dataset_train = dataset_targeted \\\n",
    "  .shuffle(SHUFFLE_BUFFER_SIZE) \\\n",
    "  .batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "  .repeat()\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84455815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:57.238121Z",
     "iopub.status.busy": "2022-04-24T22:36:57.237501Z",
     "iopub.status.idle": "2022-04-24T22:36:57.240707Z",
     "shell.execute_reply": "2022-04-24T22:36:57.241112Z"
    },
    "papermill": {
     "duration": 0.035699,
     "end_time": "2022-04-24T22:36:57.241228",
     "exception": false,
     "start_time": "2022-04-24T22:36:57.205529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:           3\n",
      "INITIAL_EPOCH:    1\n",
      "STEPS_PER_EPOCH:  23.4375\n"
     ]
    }
   ],
   "source": [
    "#const\n",
    "EPOCHS = 3 #5 seemed to work well\n",
    "INITIAL_EPOCH = 1\n",
    "STEPS_PER_EPOCH = len(allWorkoutsString) / BATCH_SIZE\n",
    "print('EPOCHS:          ', EPOCHS) \n",
    "print('INITIAL_EPOCH:   ', INITIAL_EPOCH)\n",
    "print('STEPS_PER_EPOCH: ', STEPS_PER_EPOCH) #default was 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e654fb1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:36:57.297361Z",
     "iopub.status.busy": "2022-04-24T22:36:57.296552Z",
     "iopub.status.idle": "2022-04-24T22:37:02.054801Z",
     "shell.execute_reply": "2022-04-24T22:37:02.054209Z"
    },
    "papermill": {
     "duration": 4.787254,
     "end_time": "2022-04-24T22:37:02.054937",
     "exception": false,
     "start_time": "2022-04-24T22:36:57.267683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 22:36:58.296613: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-24 22:36:59.385235: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 4s 27ms/step - loss: 0.9755\n",
      "Epoch 3/3\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.3654\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=dataset_train,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        #tqdm_callback\n",
    "       # early_stopping_callback #we want to overfit this so get rid of early stopping\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.save(\"new/baselineModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d15b7493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:37:02.133625Z",
     "iopub.status.busy": "2022-04-24T22:37:02.132770Z",
     "iopub.status.idle": "2022-04-24T22:37:02.134642Z",
     "shell.execute_reply": "2022-04-24T22:37:02.135101Z"
    },
    "papermill": {
     "duration": 0.044636,
     "end_time": "2022-04-24T22:37:02.135221",
     "exception": false,
     "start_time": "2022-04-24T22:37:02.090585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate = 1000, temperature=1.0):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    padded_start_string = start_string\n",
    "    # Converting our start string to numbers (vectorizing).\n",
    "    input_indices = np.array(tokenizer.texts_to_sequences([padded_start_string]))\n",
    "    # Empty string to store our results.\n",
    "    text_generated = []\n",
    "    # Here batch size == 1.\n",
    "   # model.reset_states()\n",
    "    for char_index in range(num_generate):\n",
    "        predictions = model(input_indices)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # Using a categorical distribution to predict the character returned by the model.\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions,\n",
    "            num_samples=1\n",
    "        )[-1, 0].numpy()\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state.\n",
    "        input_indices = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        next_character = tokenizer.sequences_to_texts(input_indices.numpy())[0]\n",
    "        text_generated.append(next_character)\n",
    "\n",
    "       # output = ''.join(text_generated)\n",
    "\n",
    "       # output = decodeWorkout(output)\n",
    "\n",
    "    return (padded_start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "261305cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:37:02.383726Z",
     "iopub.status.busy": "2022-04-24T22:37:02.382871Z",
     "iopub.status.idle": "2022-04-24T22:37:02.616740Z",
     "shell.execute_reply": "2022-04-24T22:37:02.617262Z"
    },
    "papermill": {
     "duration": 0.447364,
     "end_time": "2022-04-24T22:37:02.617478",
     "exception": false,
     "start_time": "2022-04-24T22:37:02.170114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 256)            4352      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 17)             17425     \n",
      "=================================================================\n",
      "Total params: 5,268,753\n",
      "Trainable params: 5,268,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size=VOCABULARY_SIZE\n",
    "embedding_dim=256\n",
    "rnn_units=1024\n",
    "\n",
    "simplified_batch_size = 1\n",
    "model_simplified = build_model(vocab_size, embedding_dim, rnn_units, simplified_batch_size)\n",
    "model_simplified.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model_simplified.build(tf.TensorShape([simplified_batch_size, None]))\n",
    "model_simplified.summary()\n",
    "#nonTrainedModel = keras.models.load_model(\"../input/lstmfile/simplified_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9425ebf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:37:02.707859Z",
     "iopub.status.busy": "2022-04-24T22:37:02.706906Z",
     "iopub.status.idle": "2022-04-24T22:37:02.918859Z",
     "shell.execute_reply": "2022-04-24T22:37:02.919264Z"
    },
    "papermill": {
     "duration": 0.259827,
     "end_time": "2022-04-24T22:37:02.919438",
     "exception": false,
     "start_time": "2022-04-24T22:37:02.659611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-DL:~103~80~0~80~80~0~15~15~44~23~25~11~␣\n",
      "5-DL:\n",
      "103 pushups for 80 seconds with 0 second rest \n",
      "80 situps for 80 seconds with 0 second rest \n",
      "15 squats for 15 seconds with 44 second rest \n",
      "23 burpees for 25 seconds with 11 second rest \n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model_simplified, '5-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))\n",
    "\n",
    "#allWorkoutsString.append(\"5-DL:~60~50~28~14~15~17~15~15~36~34~35~5~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~40~30~6~10~10~5~44~45~6~41~45~16~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~75~65~9~24~25~45~41~45~34~72~80~0~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~85~70~0~55~55~3~33~35~23~30~30~34~␣\")\n",
    "#allWorkoutsString.append(\"5-DL:~60~50~22~68~75~4~63~70~6~14~15~33~␣\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b37ac51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:37:02.996103Z",
     "iopub.status.busy": "2022-04-24T22:37:02.995276Z",
     "iopub.status.idle": "2022-04-24T22:37:03.189280Z",
     "shell.execute_reply": "2022-04-24T22:37:03.188853Z"
    },
    "papermill": {
     "duration": 0.234462,
     "end_time": "2022-04-24T22:37:03.189416",
     "exception": false,
     "start_time": "2022-04-24T22:37:02.954954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-DL:~18~10~21~52~65~10~48~60~7~39~50~15~␣\n",
      "4-DL:\n",
      "18 pushups for 10 seconds with 21 second rest \n",
      "52 situps for 65 seconds with 10 second rest \n",
      "48 squats for 60 seconds with 7 second rest \n",
      "39 burpees for 50 seconds with 15 second rest \n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model_simplified, '4-DL:', num_generate = 43, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9436a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:37:03.266718Z",
     "iopub.status.busy": "2022-04-24T22:37:03.265887Z",
     "iopub.status.idle": "2022-04-24T22:37:03.463443Z",
     "shell.execute_reply": "2022-04-24T22:37:03.462650Z"
    },
    "papermill": {
     "duration": 0.237714,
     "end_time": "2022-04-24T22:37:03.463557",
     "exception": false,
     "start_time": "2022-04-24T22:37:03.225843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-DL:~110~70~4~37~70~8~6~10~61~40~75~0~␣\n",
      "3-DL:\n",
      "110 pushups for 70 seconds with 4 second rest \n",
      "37 situps for 70 seconds with 8 second rest \n",
      "6 squats for 10 seconds with 61 second rest \n",
      "40 burpees for 75 seconds with 0 second rest \n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model_simplified, '3-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df5d990a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:37:03.542085Z",
     "iopub.status.busy": "2022-04-24T22:37:03.541231Z",
     "iopub.status.idle": "2022-04-24T22:37:03.744913Z",
     "shell.execute_reply": "2022-04-24T22:37:03.744292Z"
    },
    "papermill": {
     "duration": 0.245157,
     "end_time": "2022-04-24T22:37:03.745060",
     "exception": false,
     "start_time": "2022-04-24T22:37:03.499903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-DL:~27~15~4~26~80~0~38~80~0~10~25~39~␣\n",
      "2-DL:\n",
      "27 pushups for 15 seconds with 4 second rest \n",
      "26 situps for 80 seconds with 0 second rest \n",
      "38 squats for 80 seconds with 0 second rest \n",
      "10 burpees for 25 seconds with 39 second rest \n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model_simplified, '2-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5710cb63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:37:03.824521Z",
     "iopub.status.busy": "2022-04-24T22:37:03.823930Z",
     "iopub.status.idle": "2022-04-24T22:37:04.022492Z",
     "shell.execute_reply": "2022-04-24T22:37:04.023066Z"
    },
    "papermill": {
     "duration": 0.240273,
     "end_time": "2022-04-24T22:37:04.023246",
     "exception": false,
     "start_time": "2022-04-24T22:37:03.782973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-DL:~42~65~14~12~60~1~6~30~45~10~70~9~␣\n",
      "1-DL:\n",
      "42 pushups for 65 seconds with 14 second rest \n",
      "12 situps for 60 seconds with 1 second rest \n",
      "6 squats for 30 seconds with 45 second rest \n",
      "10 burpees for 70 seconds with 9 second rest \n"
     ]
    }
   ],
   "source": [
    "output = (generate_text(model_simplified, '1-DL:', num_generate = maxLength, temperature=1.0)) #make sure you pass it model_simplified\n",
    "print(output)\n",
    "print(decodeWorkout(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e5ea5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T22:37:04.103869Z",
     "iopub.status.busy": "2022-04-24T22:37:04.103136Z",
     "iopub.status.idle": "2022-04-24T22:37:04.156068Z",
     "shell.execute_reply": "2022-04-24T22:37:04.155175Z"
    },
    "papermill": {
     "duration": 0.094189,
     "end_time": "2022-04-24T22:37:04.156196",
     "exception": false,
     "start_time": "2022-04-24T22:37:04.062007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "\n",
    "model_simplified.save(\"simplified_modelMOD.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b2fe6",
   "metadata": {
    "papermill": {
     "duration": 0.037862,
     "end_time": "2022-04-24T22:37:04.233254",
     "exception": false,
     "start_time": "2022-04-24T22:37:04.195392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.327088,
   "end_time": "2022-04-24T22:37:06.983588",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-24T22:36:37.656500",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
